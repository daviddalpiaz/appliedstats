<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Model Diagnostics | Applied Statistics with R</title>
  <meta name="description" content="Chapter 13 Model Diagnostics | Applied Statistics with R" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Model Diagnostics | Applied Statistics with R" />
  <meta property="og:type" content="book" />
  
  
  <meta name="github-repo" content="daviddalpiaz/appliedstats" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Model Diagnostics | Applied Statistics with R" />
  
  
  

<meta name="author" content="David Dalpiaz" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="favicon.gif" type="image/x-icon" />
<link rel="prev" href="analysis-of-variance.html"/>
<link rel="next" href="transformations.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Applied Statistics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i><b>1.1</b> About This Book</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#conventions"><i class="fa fa-check"></i><b>1.2</b> Conventions</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.3</b> Acknowledgements</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i><b>1.4</b> License</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-r.html"><a href="introduction-to-r.html"><i class="fa fa-check"></i><b>2</b> Introduction to <code>R</code></a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#getting-started"><i class="fa fa-check"></i><b>2.1</b> Getting Started</a></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#basic-calculations"><i class="fa fa-check"></i><b>2.2</b> Basic Calculations</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-r.html"><a href="introduction-to-r.html#getting-help"><i class="fa fa-check"></i><b>2.3</b> Getting Help</a></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-r.html"><a href="introduction-to-r.html#installing-packages"><i class="fa fa-check"></i><b>2.4</b> Installing Packages</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-and-programming.html"><a href="data-and-programming.html"><i class="fa fa-check"></i><b>3</b> Data and Programming</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-and-programming.html"><a href="data-and-programming.html#data-types"><i class="fa fa-check"></i><b>3.1</b> Data Types</a></li>
<li class="chapter" data-level="3.2" data-path="data-and-programming.html"><a href="data-and-programming.html#data-structures"><i class="fa fa-check"></i><b>3.2</b> Data Structures</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="data-and-programming.html"><a href="data-and-programming.html#vectors"><i class="fa fa-check"></i><b>3.2.1</b> Vectors</a></li>
<li class="chapter" data-level="3.2.2" data-path="data-and-programming.html"><a href="data-and-programming.html#vectorization"><i class="fa fa-check"></i><b>3.2.2</b> Vectorization</a></li>
<li class="chapter" data-level="3.2.3" data-path="data-and-programming.html"><a href="data-and-programming.html#logical-operators"><i class="fa fa-check"></i><b>3.2.3</b> Logical Operators</a></li>
<li class="chapter" data-level="3.2.4" data-path="data-and-programming.html"><a href="data-and-programming.html#more-vectorization"><i class="fa fa-check"></i><b>3.2.4</b> More Vectorization</a></li>
<li class="chapter" data-level="3.2.5" data-path="data-and-programming.html"><a href="data-and-programming.html#matrices"><i class="fa fa-check"></i><b>3.2.5</b> Matrices</a></li>
<li class="chapter" data-level="3.2.6" data-path="data-and-programming.html"><a href="data-and-programming.html#lists"><i class="fa fa-check"></i><b>3.2.6</b> Lists</a></li>
<li class="chapter" data-level="3.2.7" data-path="data-and-programming.html"><a href="data-and-programming.html#data-frames"><i class="fa fa-check"></i><b>3.2.7</b> Data Frames</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data-and-programming.html"><a href="data-and-programming.html#programming-basics"><i class="fa fa-check"></i><b>3.3</b> Programming Basics</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="data-and-programming.html"><a href="data-and-programming.html#control-flow"><i class="fa fa-check"></i><b>3.3.1</b> Control Flow</a></li>
<li class="chapter" data-level="3.3.2" data-path="data-and-programming.html"><a href="data-and-programming.html#functions"><i class="fa fa-check"></i><b>3.3.2</b> Functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="summarizing-data.html"><a href="summarizing-data.html"><i class="fa fa-check"></i><b>4</b> Summarizing Data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="summarizing-data.html"><a href="summarizing-data.html#summary-statistics"><i class="fa fa-check"></i><b>4.1</b> Summary Statistics</a>
<ul>
<li class="chapter" data-level="" data-path="summarizing-data.html"><a href="summarizing-data.html#central-tendency"><i class="fa fa-check"></i>Central Tendency</a></li>
<li class="chapter" data-level="" data-path="summarizing-data.html"><a href="summarizing-data.html#spread"><i class="fa fa-check"></i>Spread</a></li>
<li class="chapter" data-level="" data-path="summarizing-data.html"><a href="summarizing-data.html#categorical"><i class="fa fa-check"></i>Categorical</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="summarizing-data.html"><a href="summarizing-data.html#plotting"><i class="fa fa-check"></i><b>4.2</b> Plotting</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="summarizing-data.html"><a href="summarizing-data.html#histograms"><i class="fa fa-check"></i><b>4.2.1</b> Histograms</a></li>
<li class="chapter" data-level="4.2.2" data-path="summarizing-data.html"><a href="summarizing-data.html#barplots"><i class="fa fa-check"></i><b>4.2.2</b> Barplots</a></li>
<li class="chapter" data-level="4.2.3" data-path="summarizing-data.html"><a href="summarizing-data.html#boxplots"><i class="fa fa-check"></i><b>4.2.3</b> Boxplots</a></li>
<li class="chapter" data-level="4.2.4" data-path="summarizing-data.html"><a href="summarizing-data.html#scatterplots"><i class="fa fa-check"></i><b>4.2.4</b> Scatterplots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probability-and-statistics-in-r.html"><a href="probability-and-statistics-in-r.html"><i class="fa fa-check"></i><b>5</b> Probability and Statistics in <code>R</code></a>
<ul>
<li class="chapter" data-level="5.1" data-path="probability-and-statistics-in-r.html"><a href="probability-and-statistics-in-r.html#probability-in-r"><i class="fa fa-check"></i><b>5.1</b> Probability in <code>R</code></a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="probability-and-statistics-in-r.html"><a href="probability-and-statistics-in-r.html#distributions"><i class="fa fa-check"></i><b>5.1.1</b> Distributions</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="probability-and-statistics-in-r.html"><a href="probability-and-statistics-in-r.html#hypothesis-tests-in-r"><i class="fa fa-check"></i><b>5.2</b> Hypothesis Tests in <code>R</code></a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="probability-and-statistics-in-r.html"><a href="probability-and-statistics-in-r.html#one-sample-t-test-review"><i class="fa fa-check"></i><b>5.2.1</b> One Sample t-Test: Review</a></li>
<li class="chapter" data-level="5.2.2" data-path="probability-and-statistics-in-r.html"><a href="probability-and-statistics-in-r.html#one-sample-t-test-example"><i class="fa fa-check"></i><b>5.2.2</b> One Sample t-Test: Example</a></li>
<li class="chapter" data-level="5.2.3" data-path="probability-and-statistics-in-r.html"><a href="probability-and-statistics-in-r.html#two-sample-t-test-review"><i class="fa fa-check"></i><b>5.2.3</b> Two Sample t-Test: Review</a></li>
<li class="chapter" data-level="5.2.4" data-path="probability-and-statistics-in-r.html"><a href="probability-and-statistics-in-r.html#two-sample-t-test-example"><i class="fa fa-check"></i><b>5.2.4</b> Two Sample t-Test: Example</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="probability-and-statistics-in-r.html"><a href="probability-and-statistics-in-r.html#simulation"><i class="fa fa-check"></i><b>5.3</b> Simulation</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="probability-and-statistics-in-r.html"><a href="probability-and-statistics-in-r.html#paired-differences"><i class="fa fa-check"></i><b>5.3.1</b> Paired Differences</a></li>
<li class="chapter" data-level="5.3.2" data-path="probability-and-statistics-in-r.html"><a href="probability-and-statistics-in-r.html#distribution-of-a-sample-mean"><i class="fa fa-check"></i><b>5.3.2</b> Distribution of a Sample Mean</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="r-resources.html"><a href="r-resources.html"><i class="fa fa-check"></i><b>6</b> <code>R</code> Resources</a>
<ul>
<li class="chapter" data-level="6.1" data-path="r-resources.html"><a href="r-resources.html#beginner-tutorials-and-references"><i class="fa fa-check"></i><b>6.1</b> Beginner Tutorials and References</a></li>
<li class="chapter" data-level="6.2" data-path="r-resources.html"><a href="r-resources.html#intermediate-references"><i class="fa fa-check"></i><b>6.2</b> Intermediate References</a></li>
<li class="chapter" data-level="6.3" data-path="r-resources.html"><a href="r-resources.html#advanced-references"><i class="fa fa-check"></i><b>6.3</b> Advanced References</a></li>
<li class="chapter" data-level="6.4" data-path="r-resources.html"><a href="r-resources.html#quick-comparisons-to-other-languages"><i class="fa fa-check"></i><b>6.4</b> Quick Comparisons to Other Languages</a></li>
<li class="chapter" data-level="6.5" data-path="r-resources.html"><a href="r-resources.html#rstudio-and-rmarkdown-videos"><i class="fa fa-check"></i><b>6.5</b> RStudio and RMarkdown Videos</a></li>
<li class="chapter" data-level="6.6" data-path="r-resources.html"><a href="r-resources.html#rmarkdown-template"><i class="fa fa-check"></i><b>6.6</b> RMarkdown Template</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>7</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#modeling"><i class="fa fa-check"></i><b>7.1</b> Modeling</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#simple-linear-regression-model"><i class="fa fa-check"></i><b>7.1.1</b> Simple Linear Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#least-squares-approach"><i class="fa fa-check"></i><b>7.2</b> Least Squares Approach</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#making-predictions"><i class="fa fa-check"></i><b>7.2.1</b> Making Predictions</a></li>
<li class="chapter" data-level="7.2.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#residuals"><i class="fa fa-check"></i><b>7.2.2</b> Residuals</a></li>
<li class="chapter" data-level="7.2.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#variance-estimation"><i class="fa fa-check"></i><b>7.2.3</b> Variance Estimation</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#decomposition-of-variation"><i class="fa fa-check"></i><b>7.3</b> Decomposition of Variation</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#coefficient-of-determination"><i class="fa fa-check"></i><b>7.3.1</b> Coefficient of Determination</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-lm-function"><i class="fa fa-check"></i><b>7.4</b> The <code>lm</code> Function</a></li>
<li class="chapter" data-level="7.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#maximum-likelihood-estimation-mle-approach"><i class="fa fa-check"></i><b>7.5</b> Maximum Likelihood Estimation (MLE) Approach</a></li>
<li class="chapter" data-level="7.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#simulating-slr"><i class="fa fa-check"></i><b>7.6</b> Simulating SLR</a></li>
<li class="chapter" data-level="7.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#history"><i class="fa fa-check"></i><b>7.7</b> History</a></li>
<li class="chapter" data-level="7.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#r-markdown"><i class="fa fa-check"></i><b>7.8</b> <code>R</code> Markdown</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html"><i class="fa fa-check"></i><b>8</b> Inference for Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#gaussmarkov-theorem"><i class="fa fa-check"></i><b>8.1</b> Gauss–Markov Theorem</a></li>
<li class="chapter" data-level="8.2" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#sampling-distributions"><i class="fa fa-check"></i><b>8.2</b> Sampling Distributions</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#simulating-sampling-distributions"><i class="fa fa-check"></i><b>8.2.1</b> Simulating Sampling Distributions</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#standard-errors"><i class="fa fa-check"></i><b>8.3</b> Standard Errors</a></li>
<li class="chapter" data-level="8.4" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#confidence-intervals-for-slope-and-intercept"><i class="fa fa-check"></i><b>8.4</b> Confidence Intervals for Slope and Intercept</a></li>
<li class="chapter" data-level="8.5" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#hypothesis-tests"><i class="fa fa-check"></i><b>8.5</b> Hypothesis Tests</a></li>
<li class="chapter" data-level="8.6" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#cars-example"><i class="fa fa-check"></i><b>8.6</b> <code>cars</code> Example</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#tests-in-r"><i class="fa fa-check"></i><b>8.6.1</b> Tests in <code>R</code></a></li>
<li class="chapter" data-level="8.6.2" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#significance-of-regression-t-test"><i class="fa fa-check"></i><b>8.6.2</b> Significance of Regression, t-Test</a></li>
<li class="chapter" data-level="8.6.3" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#confidence-intervals-in-r"><i class="fa fa-check"></i><b>8.6.3</b> Confidence Intervals in <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#confidence-interval-for-mean-response"><i class="fa fa-check"></i><b>8.7</b> Confidence Interval for Mean Response</a></li>
<li class="chapter" data-level="8.8" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#prediction-interval-for-new-observations"><i class="fa fa-check"></i><b>8.8</b> Prediction Interval for New Observations</a></li>
<li class="chapter" data-level="8.9" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#confidence-and-prediction-bands"><i class="fa fa-check"></i><b>8.9</b> Confidence and Prediction Bands</a></li>
<li class="chapter" data-level="8.10" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#significance-of-regression-f-test"><i class="fa fa-check"></i><b>8.10</b> Significance of Regression, F-Test</a></li>
<li class="chapter" data-level="8.11" data-path="inference-for-simple-linear-regression.html"><a href="inference-for-simple-linear-regression.html#r-markdown-1"><i class="fa fa-check"></i><b>8.11</b> <code>R</code> Markdown</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>9</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#matrix-approach-to-regression"><i class="fa fa-check"></i><b>9.1</b> Matrix Approach to Regression</a></li>
<li class="chapter" data-level="9.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#sampling-distribution"><i class="fa fa-check"></i><b>9.2</b> Sampling Distribution</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#single-parameter-tests"><i class="fa fa-check"></i><b>9.2.1</b> Single Parameter Tests</a></li>
<li class="chapter" data-level="9.2.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#confidence-intervals"><i class="fa fa-check"></i><b>9.2.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="9.2.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#confidence-intervals-for-mean-response"><i class="fa fa-check"></i><b>9.2.3</b> Confidence Intervals for Mean Response</a></li>
<li class="chapter" data-level="9.2.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#prediction-intervals"><i class="fa fa-check"></i><b>9.2.4</b> Prediction Intervals</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#significance-of-regression"><i class="fa fa-check"></i><b>9.3</b> Significance of Regression</a></li>
<li class="chapter" data-level="9.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#nested-models"><i class="fa fa-check"></i><b>9.4</b> Nested Models</a></li>
<li class="chapter" data-level="9.5" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#simulation-1"><i class="fa fa-check"></i><b>9.5</b> Simulation</a></li>
<li class="chapter" data-level="9.6" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#r-markdown-2"><i class="fa fa-check"></i><b>9.6</b> <code>R</code> Markdown</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="model-building.html"><a href="model-building.html"><i class="fa fa-check"></i><b>10</b> Model Building</a>
<ul>
<li class="chapter" data-level="10.1" data-path="model-building.html"><a href="model-building.html#family-form-and-fit"><i class="fa fa-check"></i><b>10.1</b> Family, Form, and Fit</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="model-building.html"><a href="model-building.html#fit"><i class="fa fa-check"></i><b>10.1.1</b> Fit</a></li>
<li class="chapter" data-level="10.1.2" data-path="model-building.html"><a href="model-building.html#form"><i class="fa fa-check"></i><b>10.1.2</b> Form</a></li>
<li class="chapter" data-level="10.1.3" data-path="model-building.html"><a href="model-building.html#family"><i class="fa fa-check"></i><b>10.1.3</b> Family</a></li>
<li class="chapter" data-level="10.1.4" data-path="model-building.html"><a href="model-building.html#assumed-model-fitted-model"><i class="fa fa-check"></i><b>10.1.4</b> Assumed Model, Fitted Model</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="model-building.html"><a href="model-building.html#explanation-versus-prediction"><i class="fa fa-check"></i><b>10.2</b> Explanation versus Prediction</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="model-building.html"><a href="model-building.html#explanation"><i class="fa fa-check"></i><b>10.2.1</b> Explanation</a></li>
<li class="chapter" data-level="10.2.2" data-path="model-building.html"><a href="model-building.html#prediction"><i class="fa fa-check"></i><b>10.2.2</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="model-building.html"><a href="model-building.html#summary"><i class="fa fa-check"></i><b>10.3</b> Summary</a></li>
<li class="chapter" data-level="10.4" data-path="model-building.html"><a href="model-building.html#r-markdown-3"><i class="fa fa-check"></i><b>10.4</b> <code>R</code> Markdown</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html"><i class="fa fa-check"></i><b>11</b> Categorical Predictors and Interactions</a>
<ul>
<li class="chapter" data-level="11.1" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#dummy-variables"><i class="fa fa-check"></i><b>11.1</b> Dummy Variables</a></li>
<li class="chapter" data-level="11.2" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#interactions"><i class="fa fa-check"></i><b>11.2</b> Interactions</a></li>
<li class="chapter" data-level="11.3" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#factor-variables"><i class="fa fa-check"></i><b>11.3</b> Factor Variables</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#factors-with-more-than-two-levels"><i class="fa fa-check"></i><b>11.3.1</b> Factors with More Than Two Levels</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#parameterization"><i class="fa fa-check"></i><b>11.4</b> Parameterization</a></li>
<li class="chapter" data-level="11.5" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#building-larger-models"><i class="fa fa-check"></i><b>11.5</b> Building Larger Models</a></li>
<li class="chapter" data-level="11.6" data-path="categorical-predictors-and-interactions.html"><a href="categorical-predictors-and-interactions.html#r-markdown-4"><i class="fa fa-check"></i><b>11.6</b> <code>R</code> Markdown</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html"><i class="fa fa-check"></i><b>12</b> Analysis of Variance</a>
<ul>
<li class="chapter" data-level="12.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#experiments"><i class="fa fa-check"></i><b>12.1</b> Experiments</a></li>
<li class="chapter" data-level="12.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#two-sample-t-test"><i class="fa fa-check"></i><b>12.2</b> Two-Sample t-Test</a></li>
<li class="chapter" data-level="12.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#one-way-anova"><i class="fa fa-check"></i><b>12.3</b> One-Way ANOVA</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#factor-variables-1"><i class="fa fa-check"></i><b>12.3.1</b> Factor Variables</a></li>
<li class="chapter" data-level="12.3.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#some-simulation"><i class="fa fa-check"></i><b>12.3.2</b> Some Simulation</a></li>
<li class="chapter" data-level="12.3.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#power"><i class="fa fa-check"></i><b>12.3.3</b> Power</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#post-hoc-testing"><i class="fa fa-check"></i><b>12.4</b> Post Hoc Testing</a></li>
<li class="chapter" data-level="12.5" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#two-way-anova"><i class="fa fa-check"></i><b>12.5</b> Two-Way ANOVA</a></li>
<li class="chapter" data-level="12.6" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#r-markdown-5"><i class="fa fa-check"></i><b>12.6</b> <code>R</code> Markdown</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="model-diagnostics.html"><a href="model-diagnostics.html"><i class="fa fa-check"></i><b>13</b> Model Diagnostics</a>
<ul>
<li class="chapter" data-level="13.1" data-path="model-diagnostics.html"><a href="model-diagnostics.html#model-assumptions"><i class="fa fa-check"></i><b>13.1</b> Model Assumptions</a></li>
<li class="chapter" data-level="13.2" data-path="model-diagnostics.html"><a href="model-diagnostics.html#checking-assumptions"><i class="fa fa-check"></i><b>13.2</b> Checking Assumptions</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="model-diagnostics.html"><a href="model-diagnostics.html#fitted-versus-residuals-plot"><i class="fa fa-check"></i><b>13.2.1</b> Fitted versus Residuals Plot</a></li>
<li class="chapter" data-level="13.2.2" data-path="model-diagnostics.html"><a href="model-diagnostics.html#breusch-pagan-test"><i class="fa fa-check"></i><b>13.2.2</b> Breusch-Pagan Test</a></li>
<li class="chapter" data-level="13.2.3" data-path="model-diagnostics.html"><a href="model-diagnostics.html#histograms-1"><i class="fa fa-check"></i><b>13.2.3</b> Histograms</a></li>
<li class="chapter" data-level="13.2.4" data-path="model-diagnostics.html"><a href="model-diagnostics.html#q-q-plots"><i class="fa fa-check"></i><b>13.2.4</b> Q-Q Plots</a></li>
<li class="chapter" data-level="13.2.5" data-path="model-diagnostics.html"><a href="model-diagnostics.html#shapiro-wilk-test"><i class="fa fa-check"></i><b>13.2.5</b> Shapiro-Wilk Test</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="model-diagnostics.html"><a href="model-diagnostics.html#unusual-observations"><i class="fa fa-check"></i><b>13.3</b> Unusual Observations</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="model-diagnostics.html"><a href="model-diagnostics.html#leverage"><i class="fa fa-check"></i><b>13.3.1</b> Leverage</a></li>
<li class="chapter" data-level="13.3.2" data-path="model-diagnostics.html"><a href="model-diagnostics.html#outliers"><i class="fa fa-check"></i><b>13.3.2</b> Outliers</a></li>
<li class="chapter" data-level="13.3.3" data-path="model-diagnostics.html"><a href="model-diagnostics.html#influence"><i class="fa fa-check"></i><b>13.3.3</b> Influence</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="model-diagnostics.html"><a href="model-diagnostics.html#data-analysis-examples"><i class="fa fa-check"></i><b>13.4</b> Data Analysis Examples</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="model-diagnostics.html"><a href="model-diagnostics.html#good-diagnostics"><i class="fa fa-check"></i><b>13.4.1</b> Good Diagnostics</a></li>
<li class="chapter" data-level="13.4.2" data-path="model-diagnostics.html"><a href="model-diagnostics.html#suspect-diagnostics"><i class="fa fa-check"></i><b>13.4.2</b> Suspect Diagnostics</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="model-diagnostics.html"><a href="model-diagnostics.html#r-markdown-6"><i class="fa fa-check"></i><b>13.5</b> <code>R</code> Markdown</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="transformations.html"><a href="transformations.html"><i class="fa fa-check"></i><b>14</b> Transformations</a>
<ul>
<li class="chapter" data-level="14.1" data-path="transformations.html"><a href="transformations.html#response-transformation"><i class="fa fa-check"></i><b>14.1</b> Response Transformation</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="transformations.html"><a href="transformations.html#variance-stabilizing-transformations"><i class="fa fa-check"></i><b>14.1.1</b> Variance Stabilizing Transformations</a></li>
<li class="chapter" data-level="14.1.2" data-path="transformations.html"><a href="transformations.html#box-cox-transformations"><i class="fa fa-check"></i><b>14.1.2</b> Box-Cox Transformations</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="transformations.html"><a href="transformations.html#predictor-transformation"><i class="fa fa-check"></i><b>14.2</b> Predictor Transformation</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="transformations.html"><a href="transformations.html#polynomials"><i class="fa fa-check"></i><b>14.2.1</b> Polynomials</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="transformations.html"><a href="transformations.html#response-transformations"><i class="fa fa-check"></i>Response Transformations</a></li>
<li class="chapter" data-level="" data-path="transformations.html"><a href="transformations.html#predictor-transformations"><i class="fa fa-check"></i>Predictor Transformations</a>
<ul>
<li class="chapter" data-level="14.2.2" data-path="transformations.html"><a href="transformations.html#a-quadratic-model"><i class="fa fa-check"></i><b>14.2.2</b> A Quadratic Model</a></li>
<li class="chapter" data-level="14.2.3" data-path="transformations.html"><a href="transformations.html#overfitting-and-extrapolation"><i class="fa fa-check"></i><b>14.2.3</b> Overfitting and Extrapolation</a></li>
<li class="chapter" data-level="14.2.4" data-path="transformations.html"><a href="transformations.html#comparing-polynomial-models"><i class="fa fa-check"></i><b>14.2.4</b> Comparing Polynomial Models</a></li>
<li class="chapter" data-level="14.2.5" data-path="transformations.html"><a href="transformations.html#poly-function-and-orthogonal-polynomials"><i class="fa fa-check"></i><b>14.2.5</b> <code>poly()</code> Function and Orthogonal Polynomials</a></li>
<li class="chapter" data-level="14.2.6" data-path="transformations.html"><a href="transformations.html#inhibit-function"><i class="fa fa-check"></i><b>14.2.6</b> Inhibit Function</a></li>
<li class="chapter" data-level="14.2.7" data-path="transformations.html"><a href="transformations.html#data-example"><i class="fa fa-check"></i><b>14.2.7</b> Data Example</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="transformations.html"><a href="transformations.html#r-markdown-7"><i class="fa fa-check"></i><b>14.3</b> <code>R</code> Markdown</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="collinearity.html"><a href="collinearity.html"><i class="fa fa-check"></i><b>15</b> Collinearity</a>
<ul>
<li class="chapter" data-level="15.1" data-path="collinearity.html"><a href="collinearity.html#exact-collinearity"><i class="fa fa-check"></i><b>15.1</b> Exact Collinearity</a></li>
<li class="chapter" data-level="15.2" data-path="collinearity.html"><a href="collinearity.html#collinearity-1"><i class="fa fa-check"></i><b>15.2</b> Collinearity</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="collinearity.html"><a href="collinearity.html#variance-inflation-factor."><i class="fa fa-check"></i><b>15.2.1</b> Variance Inflation Factor.</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="collinearity.html"><a href="collinearity.html#simulation-2"><i class="fa fa-check"></i><b>15.3</b> Simulation</a></li>
<li class="chapter" data-level="15.4" data-path="collinearity.html"><a href="collinearity.html#r-markdown-8"><i class="fa fa-check"></i><b>15.4</b> <code>R</code> Markdown</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html"><i class="fa fa-check"></i><b>16</b> Variable Selection and Model Building</a>
<ul>
<li class="chapter" data-level="16.1" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#quality-criterion"><i class="fa fa-check"></i><b>16.1</b> Quality Criterion</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#akaike-information-criterion"><i class="fa fa-check"></i><b>16.1.1</b> Akaike Information Criterion</a></li>
<li class="chapter" data-level="16.1.2" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#bayesian-information-criterion"><i class="fa fa-check"></i><b>16.1.2</b> Bayesian Information Criterion</a></li>
<li class="chapter" data-level="16.1.3" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#adjusted-r-squared"><i class="fa fa-check"></i><b>16.1.3</b> Adjusted R-Squared</a></li>
<li class="chapter" data-level="16.1.4" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#cross-validated-rmse"><i class="fa fa-check"></i><b>16.1.4</b> Cross-Validated RMSE</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#selection-procedures"><i class="fa fa-check"></i><b>16.2</b> Selection Procedures</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#backward-search"><i class="fa fa-check"></i><b>16.2.1</b> Backward Search</a></li>
<li class="chapter" data-level="16.2.2" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#forward-search"><i class="fa fa-check"></i><b>16.2.2</b> Forward Search</a></li>
<li class="chapter" data-level="16.2.3" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#stepwise-search"><i class="fa fa-check"></i><b>16.2.3</b> Stepwise Search</a></li>
<li class="chapter" data-level="16.2.4" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#exhaustive-search"><i class="fa fa-check"></i><b>16.2.4</b> Exhaustive Search</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#higher-order-terms"><i class="fa fa-check"></i><b>16.3</b> Higher Order Terms</a></li>
<li class="chapter" data-level="16.4" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#explanation-versus-prediction-1"><i class="fa fa-check"></i><b>16.4</b> Explanation versus Prediction</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#explanation-1"><i class="fa fa-check"></i><b>16.4.1</b> Explanation</a></li>
<li class="chapter" data-level="16.4.2" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#prediction-1"><i class="fa fa-check"></i><b>16.4.2</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="variable-selection-and-model-building.html"><a href="variable-selection-and-model-building.html#r-markdown-9"><i class="fa fa-check"></i><b>16.5</b> <code>R</code> Markdown</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>17</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="17.1" data-path="logistic-regression.html"><a href="logistic-regression.html#generalized-linear-models"><i class="fa fa-check"></i><b>17.1</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="17.2" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-response"><i class="fa fa-check"></i><b>17.2</b> Binary Response</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#fitting-logistic-regression"><i class="fa fa-check"></i><b>17.2.1</b> Fitting Logistic Regression</a></li>
<li class="chapter" data-level="17.2.2" data-path="logistic-regression.html"><a href="logistic-regression.html#fitting-issues"><i class="fa fa-check"></i><b>17.2.2</b> Fitting Issues</a></li>
<li class="chapter" data-level="17.2.3" data-path="logistic-regression.html"><a href="logistic-regression.html#simulation-examples"><i class="fa fa-check"></i><b>17.2.3</b> Simulation Examples</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="logistic-regression.html"><a href="logistic-regression.html#working-with-logistic-regression"><i class="fa fa-check"></i><b>17.3</b> Working with Logistic Regression</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#testing-with-glms"><i class="fa fa-check"></i><b>17.3.1</b> Testing with GLMs</a></li>
<li class="chapter" data-level="17.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#wald-test"><i class="fa fa-check"></i><b>17.3.2</b> Wald Test</a></li>
<li class="chapter" data-level="17.3.3" data-path="logistic-regression.html"><a href="logistic-regression.html#likelihood-ratio-test"><i class="fa fa-check"></i><b>17.3.3</b> Likelihood-Ratio Test</a></li>
<li class="chapter" data-level="17.3.4" data-path="logistic-regression.html"><a href="logistic-regression.html#saheart-example"><i class="fa fa-check"></i><b>17.3.4</b> <code>SAheart</code> Example</a></li>
<li class="chapter" data-level="17.3.5" data-path="logistic-regression.html"><a href="logistic-regression.html#confidence-intervals-1"><i class="fa fa-check"></i><b>17.3.5</b> Confidence Intervals</a></li>
<li class="chapter" data-level="17.3.6" data-path="logistic-regression.html"><a href="logistic-regression.html#confidence-intervals-for-mean-response-1"><i class="fa fa-check"></i><b>17.3.6</b> Confidence Intervals for Mean Response</a></li>
<li class="chapter" data-level="17.3.7" data-path="logistic-regression.html"><a href="logistic-regression.html#formula-syntax"><i class="fa fa-check"></i><b>17.3.7</b> Formula Syntax</a></li>
<li class="chapter" data-level="17.3.8" data-path="logistic-regression.html"><a href="logistic-regression.html#deviance"><i class="fa fa-check"></i><b>17.3.8</b> Deviance</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="logistic-regression.html"><a href="logistic-regression.html#classification"><i class="fa fa-check"></i><b>17.4</b> Classification</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#spam-example"><i class="fa fa-check"></i><b>17.4.1</b> <code>spam</code> Example</a></li>
<li class="chapter" data-level="17.4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#evaluating-classifiers"><i class="fa fa-check"></i><b>17.4.2</b> Evaluating Classifiers</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="logistic-regression.html"><a href="logistic-regression.html#r-markdown-10"><i class="fa fa-check"></i><b>17.5</b> <code>R</code> Markdown</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="beyond.html"><a href="beyond.html"><i class="fa fa-check"></i><b>18</b> Beyond</a>
<ul>
<li class="chapter" data-level="18.1" data-path="beyond.html"><a href="beyond.html#whats-next"><i class="fa fa-check"></i><b>18.1</b> What’s Next</a></li>
<li class="chapter" data-level="18.2" data-path="beyond.html"><a href="beyond.html#rstudio"><i class="fa fa-check"></i><b>18.2</b> RStudio</a></li>
<li class="chapter" data-level="18.3" data-path="beyond.html"><a href="beyond.html#tidy-data"><i class="fa fa-check"></i><b>18.3</b> Tidy Data</a></li>
<li class="chapter" data-level="18.4" data-path="beyond.html"><a href="beyond.html#visualization"><i class="fa fa-check"></i><b>18.4</b> Visualization</a></li>
<li class="chapter" data-level="18.5" data-path="beyond.html"><a href="beyond.html#web-applications"><i class="fa fa-check"></i><b>18.5</b> Web Applications</a></li>
<li class="chapter" data-level="18.6" data-path="beyond.html"><a href="beyond.html#experimental-design"><i class="fa fa-check"></i><b>18.6</b> Experimental Design</a></li>
<li class="chapter" data-level="18.7" data-path="beyond.html"><a href="beyond.html#machine-learning"><i class="fa fa-check"></i><b>18.7</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="18.7.1" data-path="beyond.html"><a href="beyond.html#deep-learning"><i class="fa fa-check"></i><b>18.7.1</b> Deep Learning</a></li>
</ul></li>
<li class="chapter" data-level="18.8" data-path="beyond.html"><a href="beyond.html#time-series"><i class="fa fa-check"></i><b>18.8</b> Time Series</a></li>
<li class="chapter" data-level="18.9" data-path="beyond.html"><a href="beyond.html#bayesianism"><i class="fa fa-check"></i><b>18.9</b> Bayesianism</a></li>
<li class="chapter" data-level="18.10" data-path="beyond.html"><a href="beyond.html#high-performance-computing"><i class="fa fa-check"></i><b>18.10</b> High Performance Computing</a></li>
<li class="chapter" data-level="18.11" data-path="beyond.html"><a href="beyond.html#further-r-resources"><i class="fa fa-check"></i><b>18.11</b> Further <code>R</code> Resources</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>19</b> Appendix</a></li>
<li class="divider"></li>
<li><a href="https://github.com/daviddalpiaz/appliedstats" target="blank">&copy; 2016 - 2022 David Dalpiaz</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied Statistics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="model-diagnostics" class="section level1 hasAnchor" number="13">
<h1><span class="header-section-number">Chapter 13</span> Model Diagnostics<a href="model-diagnostics.html#model-diagnostics" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<blockquote>
<p>“Your assumptions are your windows on the world. Scrub them off every once in a while, or the light won’t come in.”</p>
<p>— <strong>Isaac Asimov</strong></p>
</blockquote>
<p>After reading this chapter you will be able to:</p>
<ul>
<li>Understand the assumptions of a regression model.</li>
<li>Assess regression model assumptions using visualizations and tests.</li>
<li>Understand leverage, outliers, and influential points.</li>
<li>Be able to identify unusual observations in regression models.</li>
</ul>
<div id="model-assumptions" class="section level2 hasAnchor" number="13.1">
<h2><span class="header-section-number">13.1</span> Model Assumptions<a href="model-diagnostics.html#model-assumptions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Recall the multiple linear regression model that we have defined.</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_{p-1} x_{i(p-1)} + \epsilon_i, \qquad i = 1, 2, \ldots, n.
\]</span></p>
<p>Using matrix notation, this model can be written much more succinctly as</p>
<p><span class="math display">\[
Y = X \beta + \epsilon.
\]</span></p>
<p>Given data, we found the estimates for the <span class="math inline">\(\beta\)</span> parameters using</p>
<p><span class="math display">\[
\hat{\beta} = \left(  X^\top X  \right)^{-1}X^\top y.
\]</span></p>
<p>We then noted that these estimates had mean</p>
<p><span class="math display">\[
\text{E}[\hat{\beta}] = \beta,
\]</span></p>
<p>and variance</p>
<p><span class="math display">\[
\text{Var}[\hat{\beta}] = \sigma^2 \left(  X^\top X  \right)^{-1}.
\]</span></p>
<p>In particular, an individual parameter, say <span class="math inline">\(\hat{\beta}_j\)</span> had a normal distribution</p>
<p><span class="math display">\[
\hat{\beta}_j \sim N\left(\beta_j, \sigma^2 C_{jj}  \right)
\]</span></p>
<p>where <span class="math inline">\(C\)</span> was the matrix defined as</p>
<p><span class="math display">\[
C = \left(X^\top X\right)^{-1}.
\]</span></p>
<p>We then used this fact to define</p>
<p><span class="math display">\[
\frac{\hat{\beta}_j - \beta_j}{s_e \sqrt{C_{jj}}} \sim t_{n-p},
\]</span></p>
<p>which we used to perform hypothesis testing.</p>
<p>So far we have looked at various metrics such as RMSE, RSE, and <span class="math inline">\(R^2\)</span> to determine how well our model fits our data. Each of these in some way considers the expression</p>
<p><span class="math display">\[
\sum_{i = 1}^n (y_i - \hat{y}_i)^2.
\]</span></p>
<p>So, essentially each of these looks at how close the data points are to the model. However is that all we care about?</p>
<ul>
<li>It could be that the errors are made in a systematic way, which means that our model is misspecified. We may need additional interaction terms, or polynomial terms which we will see later.</li>
<li>It is also possible that at a particular set of predictor values, the errors are very small, but at a different set of predictor values, the errors are large.</li>
<li>Perhaps most of the errors are very small, but some are very large. This would suggest that the errors do not follow a normal distribution.</li>
</ul>
<p>Are these issues that we care about? If all we would like to do is predict, possibly not, since we would only care about the size of our errors. However, if we would like to perform inference, for example to determine if a particular predictor is important, we care a great deal. All of the distributional results, such as a <span class="math inline">\(t\)</span>-test for a single predictor, are derived under the assumptions of our model.</p>
<p>Technically, the assumptions of the model are encoded directly in a model statement such as,</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_{p-1} x_{i(p-1)} + \epsilon_i
\]</span></p>
<p>where <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2).\)</span></p>
<p>Often, the <strong>assumptions of linear regression</strong>, are stated as,</p>
<ul>
<li><strong>L</strong>inearity: the response can be written as a linear combination of the predictors. (With noise about this true linear relationship.)</li>
<li><strong>I</strong>ndependence: the errors are independent.</li>
<li><strong>N</strong>ormality: the distribution of the errors should follow a normal distribution.</li>
<li><strong>E</strong>qual Variance: the error variance is the same at any set of predictor values.</li>
</ul>
<p>The linearity assumption is encoded as</p>
<p><span class="math display">\[
\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_{p-1} x_{i(p-1)},
\]</span></p>
<p>while the remaining three, are all encoded in</p>
<p><span class="math display">\[
\epsilon_i \sim N(0, \sigma^2),
\]</span></p>
<p>since the <span class="math inline">\(\epsilon_i\)</span> are <span class="math inline">\(iid\)</span> normal random variables with constant variance.</p>
<p>If these assumptions are met, great! We can perform inference, <strong>and it is valid</strong>. If these assumptions are <em>not</em> met, we can still “perform” a <span class="math inline">\(t\)</span>-test using <code>R</code>, but the results are <strong>not valid</strong>. The distributions of the parameter estimates will not be what we expect. Hypothesis tests will then accept or reject incorrectly. Essentially, <strong>garbage in, garbage out.</strong></p>
</div>
<div id="checking-assumptions" class="section level2 hasAnchor" number="13.2">
<h2><span class="header-section-number">13.2</span> Checking Assumptions<a href="model-diagnostics.html#checking-assumptions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We’ll now look at a number of tools for checking the assumptions of a linear model. To test these tools, we’ll use data simulated from three models:</p>
<p><span class="math display">\[
\text{Model 1:} \quad Y = 3 + 5x + \epsilon, \quad \epsilon \sim N(0, 1)
\]</span></p>
<p><span class="math display">\[
\text{Model 2:} \quad Y = 3 + 5x + \epsilon, \quad \epsilon \sim N(0, x^2)
\]</span></p>
<p><span class="math display">\[
\text{Model 3:} \quad Y = 3 + 5x^2 + \epsilon, \quad \epsilon \sim N(0, 25)
\]</span></p>
<div class="sourceCode" id="cb886"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb886-1"><a href="model-diagnostics.html#cb886-1" tabindex="-1"></a>sim_1 <span class="ot">=</span> <span class="cf">function</span>(<span class="at">sample_size =</span> <span class="dv">500</span>) {</span>
<span id="cb886-2"><a href="model-diagnostics.html#cb886-2" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">runif</span>(<span class="at">n =</span> sample_size) <span class="sc">*</span> <span class="dv">5</span></span>
<span id="cb886-3"><a href="model-diagnostics.html#cb886-3" tabindex="-1"></a>  y <span class="ot">=</span> <span class="dv">3</span> <span class="sc">+</span> <span class="dv">5</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="at">n =</span> sample_size, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb886-4"><a href="model-diagnostics.html#cb886-4" tabindex="-1"></a>  <span class="fu">data.frame</span>(x, y)</span>
<span id="cb886-5"><a href="model-diagnostics.html#cb886-5" tabindex="-1"></a>}</span>
<span id="cb886-6"><a href="model-diagnostics.html#cb886-6" tabindex="-1"></a></span>
<span id="cb886-7"><a href="model-diagnostics.html#cb886-7" tabindex="-1"></a>sim_2 <span class="ot">=</span> <span class="cf">function</span>(<span class="at">sample_size =</span> <span class="dv">500</span>) {</span>
<span id="cb886-8"><a href="model-diagnostics.html#cb886-8" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">runif</span>(<span class="at">n =</span> sample_size) <span class="sc">*</span> <span class="dv">5</span></span>
<span id="cb886-9"><a href="model-diagnostics.html#cb886-9" tabindex="-1"></a>  y <span class="ot">=</span> <span class="dv">3</span> <span class="sc">+</span> <span class="dv">5</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="at">n =</span> sample_size, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> x)</span>
<span id="cb886-10"><a href="model-diagnostics.html#cb886-10" tabindex="-1"></a>  <span class="fu">data.frame</span>(x, y)</span>
<span id="cb886-11"><a href="model-diagnostics.html#cb886-11" tabindex="-1"></a>}</span>
<span id="cb886-12"><a href="model-diagnostics.html#cb886-12" tabindex="-1"></a></span>
<span id="cb886-13"><a href="model-diagnostics.html#cb886-13" tabindex="-1"></a>sim_3 <span class="ot">=</span> <span class="cf">function</span>(<span class="at">sample_size =</span> <span class="dv">500</span>) {</span>
<span id="cb886-14"><a href="model-diagnostics.html#cb886-14" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">runif</span>(<span class="at">n =</span> sample_size) <span class="sc">*</span> <span class="dv">5</span></span>
<span id="cb886-15"><a href="model-diagnostics.html#cb886-15" tabindex="-1"></a>  y <span class="ot">=</span> <span class="dv">3</span> <span class="sc">+</span> <span class="dv">5</span> <span class="sc">*</span> x <span class="sc">^</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="at">n =</span> sample_size, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">5</span>)</span>
<span id="cb886-16"><a href="model-diagnostics.html#cb886-16" tabindex="-1"></a>  <span class="fu">data.frame</span>(x, y)</span>
<span id="cb886-17"><a href="model-diagnostics.html#cb886-17" tabindex="-1"></a>}</span></code></pre></div>
<div id="fitted-versus-residuals-plot" class="section level3 hasAnchor" number="13.2.1">
<h3><span class="header-section-number">13.2.1</span> Fitted versus Residuals Plot<a href="model-diagnostics.html#fitted-versus-residuals-plot" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Probably our most useful tool will be a <strong>Fitted versus Residuals Plot</strong>. It will be useful for checking both the <strong>linearity</strong> and <strong>constant variance</strong> assumptions.</p>
<p>Data generated from Model 1 above should not show any signs of violating assumptions, so we’ll use this to see what a good fitted versus residuals plot should look like. First, we’ll simulate observations from this model.</p>
<div class="sourceCode" id="cb887"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb887-1"><a href="model-diagnostics.html#cb887-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb887-2"><a href="model-diagnostics.html#cb887-2" tabindex="-1"></a>sim_data_1 <span class="ot">=</span> <span class="fu">sim_1</span>()</span>
<span id="cb887-3"><a href="model-diagnostics.html#cb887-3" tabindex="-1"></a><span class="fu">head</span>(sim_data_1)</span></code></pre></div>
<pre><code>##          x         y
## 1 4.574030 24.773995
## 2 4.685377 26.475936
## 3 1.430698  8.954993
## 4 4.152238 23.951210
## 5 3.208728 20.341344
## 6 2.595480 14.943525</code></pre>
<p>We then fit the model and add the fitted line to a scatterplot.</p>
<div class="sourceCode" id="cb889"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb889-1"><a href="model-diagnostics.html#cb889-1" tabindex="-1"></a><span class="fu">plot</span>(y <span class="sc">~</span> x, <span class="at">data =</span> sim_data_1, <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">pch =</span> <span class="dv">20</span>,</span>
<span id="cb889-2"><a href="model-diagnostics.html#cb889-2" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Data from Model 1&quot;</span>)</span>
<span id="cb889-3"><a href="model-diagnostics.html#cb889-3" tabindex="-1"></a>fit_1 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> sim_data_1)</span>
<span id="cb889-4"><a href="model-diagnostics.html#cb889-4" tabindex="-1"></a><span class="fu">abline</span>(fit_1, <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>We now plot a fitted versus residuals plot. Note, this is residuals on the <span class="math inline">\(y\)</span>-axis despite the ordering in the name. Sometimes you will see this called a residuals versus fitted, or residuals versus predicted plot.</p>
<div class="sourceCode" id="cb890"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb890-1"><a href="model-diagnostics.html#cb890-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">fitted</span>(fit_1), <span class="fu">resid</span>(fit_1), <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">pch =</span> <span class="dv">20</span>,</span>
<span id="cb890-2"><a href="model-diagnostics.html#cb890-2" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Fitted&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Residuals&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Data from Model 1&quot;</span>)</span>
<span id="cb890-3"><a href="model-diagnostics.html#cb890-3" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>We should look for two things in this plot.</p>
<ul>
<li>At any fitted value, the mean of the residuals should be roughly 0. If this is the case, the <em>linearity</em> assumption is valid. For this reason, we generally add a horizontal line at <span class="math inline">\(y = 0\)</span> to emphasize this point.</li>
<li>At every fitted value, the spread of the residuals should be roughly the same. If this is the case, the <em>constant variance</em> assumption is valid.</li>
</ul>
<p>Here we see this is the case for both.</p>
<p>To get a better idea of how a fitted versus residuals plot can be useful, we will simulate from models with violated assumptions.</p>
<p>Model 2 is an example of non-constant variance. In this case, the variance is larger for larger values of the predictor variable <span class="math inline">\(x\)</span>.</p>
<div class="sourceCode" id="cb891"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb891-1"><a href="model-diagnostics.html#cb891-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb891-2"><a href="model-diagnostics.html#cb891-2" tabindex="-1"></a>sim_data_2 <span class="ot">=</span> <span class="fu">sim_2</span>()</span>
<span id="cb891-3"><a href="model-diagnostics.html#cb891-3" tabindex="-1"></a>fit_2 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> sim_data_2)</span>
<span id="cb891-4"><a href="model-diagnostics.html#cb891-4" tabindex="-1"></a><span class="fu">plot</span>(y <span class="sc">~</span> x, <span class="at">data =</span> sim_data_2, <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">pch =</span> <span class="dv">20</span>,</span>
<span id="cb891-5"><a href="model-diagnostics.html#cb891-5" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Data from Model 2&quot;</span>)</span>
<span id="cb891-6"><a href="model-diagnostics.html#cb891-6" tabindex="-1"></a><span class="fu">abline</span>(fit_2, <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>This actually is rather easy to see here by adding the fitted line to a scatterplot. This is because we are only performing simple linear regression. With multiple regression, a fitted versus residuals plot is a necessity, since adding a fitted regression to a scatterplot isn’t exactly possible.</p>
<div class="sourceCode" id="cb892"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb892-1"><a href="model-diagnostics.html#cb892-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">fitted</span>(fit_2), <span class="fu">resid</span>(fit_2), <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">pch =</span> <span class="dv">20</span>,</span>
<span id="cb892-2"><a href="model-diagnostics.html#cb892-2" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Fitted&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Residuals&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Data from Model 2&quot;</span>)</span>
<span id="cb892-3"><a href="model-diagnostics.html#cb892-3" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>On the fitted versus residuals plot, we see two things very clearly. For any fitted value, the residuals seem roughly centered at 0. This is good! The linearity assumption is not violated. However, we also see very clearly, that for larger fitted values, the spread of the residuals is larger. This is bad! The constant variance assumption is violated here.</p>
<p>Now we will demonstrate a model which does not meet the linearity assumption. Model 3 is an example of a model where <span class="math inline">\(Y\)</span> is not a linear combination of the predictors. In this case the predictor is <span class="math inline">\(x\)</span>, but the model uses <span class="math inline">\(x^2\)</span>. (We’ll see later that this is something that a “linear” model can deal with. The fix is simple, just make <span class="math inline">\(x^2\)</span> a predictor!)</p>
<div class="sourceCode" id="cb893"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb893-1"><a href="model-diagnostics.html#cb893-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb893-2"><a href="model-diagnostics.html#cb893-2" tabindex="-1"></a>sim_data_3 <span class="ot">=</span> <span class="fu">sim_3</span>()</span>
<span id="cb893-3"><a href="model-diagnostics.html#cb893-3" tabindex="-1"></a>fit_3 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> sim_data_3)</span>
<span id="cb893-4"><a href="model-diagnostics.html#cb893-4" tabindex="-1"></a><span class="fu">plot</span>(y <span class="sc">~</span> x, <span class="at">data =</span> sim_data_3, <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">pch =</span> <span class="dv">20</span>,</span>
<span id="cb893-5"><a href="model-diagnostics.html#cb893-5" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Data from Model 3&quot;</span>)</span>
<span id="cb893-6"><a href="model-diagnostics.html#cb893-6" tabindex="-1"></a><span class="fu">abline</span>(fit_3, <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Again, this is rather clear on the scatterplot, but again, we wouldn’t be able to check this plot for multiple regression.</p>
<div class="sourceCode" id="cb894"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb894-1"><a href="model-diagnostics.html#cb894-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">fitted</span>(fit_3), <span class="fu">resid</span>(fit_3), <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">pch =</span> <span class="dv">20</span>,</span>
<span id="cb894-2"><a href="model-diagnostics.html#cb894-2" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Fitted&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Residuals&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Data from Model 3&quot;</span>)</span>
<span id="cb894-3"><a href="model-diagnostics.html#cb894-3" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>This time on the fitted versus residuals plot, for any fitted value, the spread of the residuals is about the same. However, they are not even close to centered at zero! At small and large fitted values the model is underestimating, while at medium fitted values, the model is overestimating. These are systematic errors, not random noise. So the constant variance assumption is met, but the linearity assumption is violated. The form of our model is simply wrong. We’re trying to fit a line to a curve!</p>
</div>
<div id="breusch-pagan-test" class="section level3 hasAnchor" number="13.2.2">
<h3><span class="header-section-number">13.2.2</span> Breusch-Pagan Test<a href="model-diagnostics.html#breusch-pagan-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Constant variance is often called <strong>homoscedasticity</strong>. Conversely, non-constant variance is called <strong>heteroscedasticity</strong>. We’ve seen how we can use a fitted versus residuals plot to look for these attributes.</p>
<p>While a fitted versus residuals plot can give us an idea about homoscedasticity, sometimes we would prefer a more formal test. There are many tests for constant variance, but here we will present one, the <a href="https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test" target="_blank"><strong>Breusch-Pagan Test</strong></a>. The exact details of the test will be omitted here, but importantly the null and alternative can be considered to be,</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: Homoscedasticity. The errors have constant variance about the true model.</li>
<li><span class="math inline">\(H_1\)</span>: Heteroscedasticity. The errors have non-constant variance about the true model.</li>
</ul>
<p>Isn’t that convenient? A test that will specifically test the <strong>constant variance</strong> assumption.</p>
<p>The Breusch-Pagan Test can not be performed by default in <code>R</code>, however the function <code>bptest</code> in the <code>lmtest</code> package implements the test.</p>
<div class="sourceCode" id="cb895"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb895-1"><a href="model-diagnostics.html#cb895-1" tabindex="-1"></a><span class="co">#install.packages(&quot;lmtest&quot;)</span></span>
<span id="cb895-2"><a href="model-diagnostics.html#cb895-2" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span></code></pre></div>
<p>Let’s try it on the three models we fit above. Recall,</p>
<ul>
<li><code>fit_1</code> had no violation of assumptions,</li>
<li><code>fit_2</code> violated the constant variance assumption, but not linearity,</li>
<li><code>fit_3</code> violated linearity, but not constant variance.</li>
</ul>
<div class="sourceCode" id="cb896"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb896-1"><a href="model-diagnostics.html#cb896-1" tabindex="-1"></a><span class="fu">bptest</span>(fit_1)</span></code></pre></div>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  fit_1
## BP = 1.0234, df = 1, p-value = 0.3117</code></pre>
<p>For <code>fit_1</code> we see a large p-value, so we do not reject the null of homoscedasticity, which is what we would expect.</p>
<div class="sourceCode" id="cb898"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb898-1"><a href="model-diagnostics.html#cb898-1" tabindex="-1"></a><span class="fu">bptest</span>(fit_2)</span></code></pre></div>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  fit_2
## BP = 76.693, df = 1, p-value &lt; 2.2e-16</code></pre>
<p>For <code>fit_2</code> we see a small p-value, so we reject the null of homoscedasticity. The constant variance assumption is violated. This matches our findings with a fitted versus residuals plot.</p>
<div class="sourceCode" id="cb900"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb900-1"><a href="model-diagnostics.html#cb900-1" tabindex="-1"></a><span class="fu">bptest</span>(fit_3)</span></code></pre></div>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  fit_3
## BP = 0.33466, df = 1, p-value = 0.5629</code></pre>
<p>Lastly, for <code>fit_3</code> we again see a large p-value, so we do not reject the null of homoscedasticity, which matches our findings with a fitted versus residuals plot.</p>
</div>
<div id="histograms-1" class="section level3 hasAnchor" number="13.2.3">
<h3><span class="header-section-number">13.2.3</span> Histograms<a href="model-diagnostics.html#histograms-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We have a number of tools for assessing the normality assumption. The most obvious would be to make a histogram of the residuals. If it appears roughly normal, then we’ll believe the errors could truly be normal.</p>
<div class="sourceCode" id="cb902"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb902-1"><a href="model-diagnostics.html#cb902-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb902-2"><a href="model-diagnostics.html#cb902-2" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">resid</span>(fit_1),</span>
<span id="cb902-3"><a href="model-diagnostics.html#cb902-3" tabindex="-1"></a>     <span class="at">xlab   =</span> <span class="st">&quot;Residuals&quot;</span>,</span>
<span id="cb902-4"><a href="model-diagnostics.html#cb902-4" tabindex="-1"></a>     <span class="at">main   =</span> <span class="st">&quot;Histogram of Residuals, fit_1&quot;</span>,</span>
<span id="cb902-5"><a href="model-diagnostics.html#cb902-5" tabindex="-1"></a>     <span class="at">col    =</span> <span class="st">&quot;darkorange&quot;</span>,</span>
<span id="cb902-6"><a href="model-diagnostics.html#cb902-6" tabindex="-1"></a>     <span class="at">border =</span> <span class="st">&quot;dodgerblue&quot;</span>,</span>
<span id="cb902-7"><a href="model-diagnostics.html#cb902-7" tabindex="-1"></a>     <span class="at">breaks =</span> <span class="dv">20</span>)</span>
<span id="cb902-8"><a href="model-diagnostics.html#cb902-8" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">resid</span>(fit_2),</span>
<span id="cb902-9"><a href="model-diagnostics.html#cb902-9" tabindex="-1"></a>     <span class="at">xlab   =</span> <span class="st">&quot;Residuals&quot;</span>,</span>
<span id="cb902-10"><a href="model-diagnostics.html#cb902-10" tabindex="-1"></a>     <span class="at">main   =</span> <span class="st">&quot;Histogram of Residuals, fit_2&quot;</span>,</span>
<span id="cb902-11"><a href="model-diagnostics.html#cb902-11" tabindex="-1"></a>     <span class="at">col    =</span> <span class="st">&quot;darkorange&quot;</span>,</span>
<span id="cb902-12"><a href="model-diagnostics.html#cb902-12" tabindex="-1"></a>     <span class="at">border =</span> <span class="st">&quot;dodgerblue&quot;</span>,</span>
<span id="cb902-13"><a href="model-diagnostics.html#cb902-13" tabindex="-1"></a>     <span class="at">breaks =</span> <span class="dv">20</span>)</span>
<span id="cb902-14"><a href="model-diagnostics.html#cb902-14" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">resid</span>(fit_3),</span>
<span id="cb902-15"><a href="model-diagnostics.html#cb902-15" tabindex="-1"></a>     <span class="at">xlab   =</span> <span class="st">&quot;Residuals&quot;</span>,</span>
<span id="cb902-16"><a href="model-diagnostics.html#cb902-16" tabindex="-1"></a>     <span class="at">main   =</span> <span class="st">&quot;Histogram of Residuals, fit_3&quot;</span>,</span>
<span id="cb902-17"><a href="model-diagnostics.html#cb902-17" tabindex="-1"></a>     <span class="at">col    =</span> <span class="st">&quot;darkorange&quot;</span>,</span>
<span id="cb902-18"><a href="model-diagnostics.html#cb902-18" tabindex="-1"></a>     <span class="at">border =</span> <span class="st">&quot;dodgerblue&quot;</span>,</span>
<span id="cb902-19"><a href="model-diagnostics.html#cb902-19" tabindex="-1"></a>     <span class="at">breaks =</span> <span class="dv">20</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-14-1.png" width="1440" style="display: block; margin: auto;" /></p>
<p>Above are histograms for each of the three regression models we have been considering. Notice that the first, for <code>fit_1</code> appears very normal. The third, for <code>fit_3</code>, appears to be very non-normal. However <code>fit_2</code> is not as clear. It does have a rough bell shape, however, it also has a very sharp peak. For this reason we will usually use more powerful tools such as <strong>Q-Q plots</strong> and the <strong>Shapiro-Wilk test</strong> for assessing the normality of errors.</p>
</div>
<div id="q-q-plots" class="section level3 hasAnchor" number="13.2.4">
<h3><span class="header-section-number">13.2.4</span> Q-Q Plots<a href="model-diagnostics.html#q-q-plots" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Another visual method for assessing the normality of errors, which is more powerful than a histogram, is a normal quantile-quantile plot, or <strong>Q-Q plot</strong> for short.</p>
<p>In <code>R</code> these are very easy to make. The <code>qqnorm()</code> function plots the points, and the <code>qqline()</code> function adds the necessary line. We create a Q-Q plot for the residuals of <code>fit_1</code> to check if the errors could truly be normally distributed.</p>
<div class="sourceCode" id="cb903"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb903-1"><a href="model-diagnostics.html#cb903-1" tabindex="-1"></a><span class="fu">qqnorm</span>(<span class="fu">resid</span>(fit_1), <span class="at">main =</span> <span class="st">&quot;Normal Q-Q Plot, fit_1&quot;</span>, <span class="at">col =</span> <span class="st">&quot;darkgrey&quot;</span>)</span>
<span id="cb903-2"><a href="model-diagnostics.html#cb903-2" tabindex="-1"></a><span class="fu">qqline</span>(<span class="fu">resid</span>(fit_1), <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>In short, if the points of the plot do not closely follow a straight line, this would suggest that the data do not come from a normal distribution.</p>
<p>The calculations required to create the plot vary depending on the implementation, but essentially the <span class="math inline">\(y\)</span>-axis is the sorted data (observed, or sample quantiles), and the <span class="math inline">\(x\)</span>-axis is the values we would expect if the data did come from a normal distribution (theoretical quantiles).</p>
<p>The <a href="http://en.wikipedia.org/wiki/Normal_probability_plot" target="_blank">Wikipedia page for Normal probability plots</a> gives details on how this is implemented in <code>R</code> if you are interested.</p>
<p>Also, to get a better idea of how Q-Q plots work, here is a quick function which creates a Q-Q plot:</p>
<div class="sourceCode" id="cb904"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb904-1"><a href="model-diagnostics.html#cb904-1" tabindex="-1"></a>qq_plot <span class="ot">=</span> <span class="cf">function</span>(e) {</span>
<span id="cb904-2"><a href="model-diagnostics.html#cb904-2" tabindex="-1"></a></span>
<span id="cb904-3"><a href="model-diagnostics.html#cb904-3" tabindex="-1"></a>  n <span class="ot">=</span> <span class="fu">length</span>(e)</span>
<span id="cb904-4"><a href="model-diagnostics.html#cb904-4" tabindex="-1"></a>  normal_quantiles <span class="ot">=</span> <span class="fu">qnorm</span>(((<span class="dv">1</span><span class="sc">:</span>n <span class="sc">-</span> <span class="fl">0.5</span>) <span class="sc">/</span> n))</span>
<span id="cb904-5"><a href="model-diagnostics.html#cb904-5" tabindex="-1"></a>  <span class="co"># normal_quantiles = qnorm(((1:n) / (n + 1)))</span></span>
<span id="cb904-6"><a href="model-diagnostics.html#cb904-6" tabindex="-1"></a></span>
<span id="cb904-7"><a href="model-diagnostics.html#cb904-7" tabindex="-1"></a>  <span class="co"># plot theoretical verus observed quantiles</span></span>
<span id="cb904-8"><a href="model-diagnostics.html#cb904-8" tabindex="-1"></a>  <span class="fu">plot</span>(normal_quantiles, <span class="fu">sort</span>(e),</span>
<span id="cb904-9"><a href="model-diagnostics.html#cb904-9" tabindex="-1"></a>       <span class="at">xlab =</span> <span class="fu">c</span>(<span class="st">&quot;Theoretical Quantiles&quot;</span>),</span>
<span id="cb904-10"><a href="model-diagnostics.html#cb904-10" tabindex="-1"></a>       <span class="at">ylab =</span> <span class="fu">c</span>(<span class="st">&quot;Sample Quantiles&quot;</span>),</span>
<span id="cb904-11"><a href="model-diagnostics.html#cb904-11" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&quot;darkgrey&quot;</span>)</span>
<span id="cb904-12"><a href="model-diagnostics.html#cb904-12" tabindex="-1"></a>  <span class="fu">title</span>(<span class="st">&quot;Normal Q-Q Plot&quot;</span>)</span>
<span id="cb904-13"><a href="model-diagnostics.html#cb904-13" tabindex="-1"></a></span>
<span id="cb904-14"><a href="model-diagnostics.html#cb904-14" tabindex="-1"></a>  <span class="co"># calculate line through the first and third quartiles</span></span>
<span id="cb904-15"><a href="model-diagnostics.html#cb904-15" tabindex="-1"></a>  slope     <span class="ot">=</span> (<span class="fu">quantile</span>(e, <span class="fl">0.75</span>) <span class="sc">-</span> <span class="fu">quantile</span>(e, <span class="fl">0.25</span>)) <span class="sc">/</span> (<span class="fu">qnorm</span>(<span class="fl">0.75</span>) <span class="sc">-</span> <span class="fu">qnorm</span>(<span class="fl">0.25</span>))</span>
<span id="cb904-16"><a href="model-diagnostics.html#cb904-16" tabindex="-1"></a>  intercept <span class="ot">=</span> <span class="fu">quantile</span>(e, <span class="fl">0.25</span>) <span class="sc">-</span> slope <span class="sc">*</span> <span class="fu">qnorm</span>(<span class="fl">0.25</span>)</span>
<span id="cb904-17"><a href="model-diagnostics.html#cb904-17" tabindex="-1"></a></span>
<span id="cb904-18"><a href="model-diagnostics.html#cb904-18" tabindex="-1"></a>  <span class="co"># add to existing plot</span></span>
<span id="cb904-19"><a href="model-diagnostics.html#cb904-19" tabindex="-1"></a>  <span class="fu">abline</span>(intercept, slope, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>)</span>
<span id="cb904-20"><a href="model-diagnostics.html#cb904-20" tabindex="-1"></a>}</span></code></pre></div>
<p>We can then verify that it is essentially equivalent to using <code>qqnorm()</code> and <code>qqline()</code> in <code>R</code>.</p>
<div class="sourceCode" id="cb905"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb905-1"><a href="model-diagnostics.html#cb905-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">420</span>)</span>
<span id="cb905-2"><a href="model-diagnostics.html#cb905-2" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">0</span> , <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb905-3"><a href="model-diagnostics.html#cb905-3" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb905-4"><a href="model-diagnostics.html#cb905-4" tabindex="-1"></a><span class="fu">qqnorm</span>(x, <span class="at">col =</span> <span class="st">&quot;darkgrey&quot;</span>)</span>
<span id="cb905-5"><a href="model-diagnostics.html#cb905-5" tabindex="-1"></a><span class="fu">qqline</span>(x, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>)</span>
<span id="cb905-6"><a href="model-diagnostics.html#cb905-6" tabindex="-1"></a><span class="fu">qq_plot</span>(x)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-17-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>To get a better idea of what “close to the line” means, we perform a number of simulations, and create Q-Q plots.</p>
<p>First we simulate data from a normal distribution with different sample sizes, and each time create a Q-Q plot.</p>
<div class="sourceCode" id="cb906"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb906-1"><a href="model-diagnostics.html#cb906-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb906-2"><a href="model-diagnostics.html#cb906-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">420</span>)</span>
<span id="cb906-3"><a href="model-diagnostics.html#cb906-3" tabindex="-1"></a><span class="fu">qq_plot</span>(<span class="fu">rnorm</span>(<span class="dv">10</span>))</span>
<span id="cb906-4"><a href="model-diagnostics.html#cb906-4" tabindex="-1"></a><span class="fu">qq_plot</span>(<span class="fu">rnorm</span>(<span class="dv">25</span>))</span>
<span id="cb906-5"><a href="model-diagnostics.html#cb906-5" tabindex="-1"></a><span class="fu">qq_plot</span>(<span class="fu">rnorm</span>(<span class="dv">100</span>))</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-18-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p>Since this data <strong>is</strong> sampled from a normal distribution, these are all, by definition, good Q-Q plots. The points are “close to the line” and we would conclude that this data could have been sampled from a normal distribution. Notice in the first plot, one point is <em>somewhat</em> far from the line, but just one point, in combination with the small sample size, is not enough to make us worried. We see with the large sample size, all of the points are rather close to the line.</p>
<p>Next, we simulate data from a <span class="math inline">\(t\)</span> distribution with a small degrees of freedom, for different sample sizes.</p>
<div class="sourceCode" id="cb907"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb907-1"><a href="model-diagnostics.html#cb907-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb907-2"><a href="model-diagnostics.html#cb907-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">420</span>)</span>
<span id="cb907-3"><a href="model-diagnostics.html#cb907-3" tabindex="-1"></a><span class="fu">qq_plot</span>(<span class="fu">rt</span>(<span class="dv">10</span>, <span class="at">df =</span> <span class="dv">4</span>))</span>
<span id="cb907-4"><a href="model-diagnostics.html#cb907-4" tabindex="-1"></a><span class="fu">qq_plot</span>(<span class="fu">rt</span>(<span class="dv">25</span>, <span class="at">df =</span> <span class="dv">4</span>))</span>
<span id="cb907-5"><a href="model-diagnostics.html#cb907-5" tabindex="-1"></a><span class="fu">qq_plot</span>(<span class="fu">rt</span>(<span class="dv">100</span>, <span class="at">df =</span> <span class="dv">4</span>))</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-19-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p>Recall that as the degrees of freedom for a <span class="math inline">\(t\)</span> distribution become larger, the distribution becomes more and more similar to a normal. Here, using 4 degrees of freedom, we have a distribution that is somewhat normal, it is symmetrical and roughly bell-shaped, however it has “fat tails.” This presents itself clearly in the third panel. While many of the points are close to the line, at the edges, there are large discrepancies. This indicates that the values are too small (negative) or too large (positive) compared to what we would expect for a normal distribution. So for the sample size of <code>100</code>, we would conclude that the normality assumption is violated. (If these were residuals of a model.) For sample sizes of <code>10</code> and <code>25</code> we may be suspicious, but not entirely confident. Reading Q-Q plots, is a bit of an art, not completely a science.</p>
<p>Next, we simulate data from an exponential distribution.</p>
<div class="sourceCode" id="cb908"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb908-1"><a href="model-diagnostics.html#cb908-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb908-2"><a href="model-diagnostics.html#cb908-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">420</span>)</span>
<span id="cb908-3"><a href="model-diagnostics.html#cb908-3" tabindex="-1"></a><span class="fu">qq_plot</span>(<span class="fu">rexp</span>(<span class="dv">10</span>))</span>
<span id="cb908-4"><a href="model-diagnostics.html#cb908-4" tabindex="-1"></a><span class="fu">qq_plot</span>(<span class="fu">rexp</span>(<span class="dv">25</span>))</span>
<span id="cb908-5"><a href="model-diagnostics.html#cb908-5" tabindex="-1"></a><span class="fu">qq_plot</span>(<span class="fu">rexp</span>(<span class="dv">100</span>))</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-20-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p>This is a distribution that is not very similar to a normal, so in all three cases, we see points that are far from the lines, so we would think that the normality assumption is violated.</p>
<p>For a better understanding of which Q-Q plots are “good,” repeat the simulations above a number of times (without setting the seed) and pay attention to the differences between those that are simulated from normal, and those that are not. Also consider different sample sizes and distribution parameters.</p>
<p>Returning to our three regressions, recall,</p>
<ul>
<li><code>fit_1</code> had no violation of assumptions,</li>
<li><code>fit_2</code> violated the constant variance assumption, but not linearity,</li>
<li><code>fit_3</code> violated linearity, but not constant variance.</li>
</ul>
<p>We’ll now create a Q-Q plot for each to assess normality of errors.</p>
<div class="sourceCode" id="cb909"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb909-1"><a href="model-diagnostics.html#cb909-1" tabindex="-1"></a><span class="fu">qqnorm</span>(<span class="fu">resid</span>(fit_1), <span class="at">main =</span> <span class="st">&quot;Normal Q-Q Plot, fit_1&quot;</span>, <span class="at">col =</span> <span class="st">&quot;darkgrey&quot;</span>)</span>
<span id="cb909-2"><a href="model-diagnostics.html#cb909-2" tabindex="-1"></a><span class="fu">qqline</span>(<span class="fu">resid</span>(fit_1), <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-21-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>For <code>fit_1</code>, we have a near perfect Q-Q plot. We would believe the errors follow a normal distribution.</p>
<div class="sourceCode" id="cb910"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb910-1"><a href="model-diagnostics.html#cb910-1" tabindex="-1"></a><span class="fu">qqnorm</span>(<span class="fu">resid</span>(fit_2), <span class="at">main =</span> <span class="st">&quot;Normal Q-Q Plot, fit_2&quot;</span>, <span class="at">col =</span> <span class="st">&quot;darkgrey&quot;</span>)</span>
<span id="cb910-2"><a href="model-diagnostics.html#cb910-2" tabindex="-1"></a><span class="fu">qqline</span>(<span class="fu">resid</span>(fit_2), <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-22-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>For <code>fit_2</code>, we have a suspect Q-Q plot. We would probably <strong>not</strong> believe the errors follow a normal distribution.</p>
<div class="sourceCode" id="cb911"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb911-1"><a href="model-diagnostics.html#cb911-1" tabindex="-1"></a><span class="fu">qqnorm</span>(<span class="fu">resid</span>(fit_3), <span class="at">main =</span> <span class="st">&quot;Normal Q-Q Plot, fit_3&quot;</span>, <span class="at">col =</span> <span class="st">&quot;darkgrey&quot;</span>)</span>
<span id="cb911-2"><a href="model-diagnostics.html#cb911-2" tabindex="-1"></a><span class="fu">qqline</span>(<span class="fu">resid</span>(fit_3), <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-23-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Lastly, for <code>fit_3</code>, we again have a suspect Q-Q plot. We would probably <strong>not</strong> believe the errors follow a normal distribution.</p>
</div>
<div id="shapiro-wilk-test" class="section level3 hasAnchor" number="13.2.5">
<h3><span class="header-section-number">13.2.5</span> Shapiro-Wilk Test<a href="model-diagnostics.html#shapiro-wilk-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Histograms and Q-Q Plots give a nice visual representation of the residuals distribution, however if we are interested in formal testing, there are a number of options available. A commonly used test is the <strong>Shapiro–Wilk test</strong>, which is implemented in <code>R</code>.</p>
<div class="sourceCode" id="cb912"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb912-1"><a href="model-diagnostics.html#cb912-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb912-2"><a href="model-diagnostics.html#cb912-2" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">rnorm</span>(<span class="dv">25</span>))</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  rnorm(25)
## W = 0.9499, p-value = 0.2495</code></pre>
<div class="sourceCode" id="cb914"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb914-1"><a href="model-diagnostics.html#cb914-1" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">rexp</span>(<span class="dv">25</span>))</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  rexp(25)
## W = 0.71164, p-value = 1.05e-05</code></pre>
<p>This gives us the value of the test statistic and its p-value. The null hypothesis assumes the data were sampled from a normal distribution, thus a small p-value indicates we believe there is only a small probability the data could have been sampled from a normal distribution.</p>
<p>For details, see: <a href="https://en.wikipedia.org/wiki/Shapiro-Wilk_test" target="_blank">Wikipedia: Shapiro–Wilk test.</a></p>
<p>In the above examples, we see we fail to reject for the data sampled from normal, and reject on the non-normal data, for any reasonable <span class="math inline">\(\alpha\)</span>.</p>
<p>Returning again to <code>fit_1</code>, <code>fit_2</code>, and <code>fit_3</code>, we see the result of running <code>shapiro.test()</code> on the residuals of each, returns a result for each that matches decisions based on the Q-Q plots.</p>
<div class="sourceCode" id="cb916"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb916-1"><a href="model-diagnostics.html#cb916-1" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">resid</span>(fit_1))</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resid(fit_1)
## W = 0.99858, p-value = 0.9622</code></pre>
<div class="sourceCode" id="cb918"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb918-1"><a href="model-diagnostics.html#cb918-1" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">resid</span>(fit_2))</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resid(fit_2)
## W = 0.93697, p-value = 1.056e-13</code></pre>
<div class="sourceCode" id="cb920"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb920-1"><a href="model-diagnostics.html#cb920-1" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">resid</span>(fit_3))</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resid(fit_3)
## W = 0.97643, p-value = 3.231e-07</code></pre>
</div>
</div>
<div id="unusual-observations" class="section level2 hasAnchor" number="13.3">
<h2><span class="header-section-number">13.3</span> Unusual Observations<a href="model-diagnostics.html#unusual-observations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In addition to checking the assumptions of regression, we also look for any “unusual observations” in the data. Often a small number of data points can have an extremely large influence on a regression, sometimes so much so that the regression assumptions are violated as a result of these points.</p>
<p>The following three plots are inspired by an example from <a href="http://www.maths.bath.ac.uk/~jjf23/LMR/" target="_blank">Linear Models with R</a>.</p>
<div class="sourceCode" id="cb922"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb922-1"><a href="model-diagnostics.html#cb922-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb922-2"><a href="model-diagnostics.html#cb922-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb922-3"><a href="model-diagnostics.html#cb922-3" tabindex="-1"></a>ex_data  <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,</span>
<span id="cb922-4"><a href="model-diagnostics.html#cb922-4" tabindex="-1"></a>                      <span class="at">y =</span> <span class="dv">10</span><span class="sc">:</span><span class="dv">1</span> <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">10</span>))</span>
<span id="cb922-5"><a href="model-diagnostics.html#cb922-5" tabindex="-1"></a>ex_model <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> ex_data)</span>
<span id="cb922-6"><a href="model-diagnostics.html#cb922-6" tabindex="-1"></a></span>
<span id="cb922-7"><a href="model-diagnostics.html#cb922-7" tabindex="-1"></a><span class="co"># low leverage, large residual, small influence</span></span>
<span id="cb922-8"><a href="model-diagnostics.html#cb922-8" tabindex="-1"></a>point_1 <span class="ot">=</span> <span class="fu">c</span>(<span class="fl">5.4</span>, <span class="dv">11</span>)</span>
<span id="cb922-9"><a href="model-diagnostics.html#cb922-9" tabindex="-1"></a>ex_data_1 <span class="ot">=</span> <span class="fu">rbind</span>(ex_data, point_1)</span>
<span id="cb922-10"><a href="model-diagnostics.html#cb922-10" tabindex="-1"></a>model_1 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> ex_data_1)</span>
<span id="cb922-11"><a href="model-diagnostics.html#cb922-11" tabindex="-1"></a><span class="fu">plot</span>(y <span class="sc">~</span> x, <span class="at">data =</span> ex_data_1, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>,</span>
<span id="cb922-12"><a href="model-diagnostics.html#cb922-12" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Low Leverage, Large Residual, Small Influence&quot;</span>)</span>
<span id="cb922-13"><a href="model-diagnostics.html#cb922-13" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x =</span> point_1[<span class="dv">1</span>], <span class="at">y =</span> point_1[<span class="dv">2</span>], <span class="at">pch =</span> <span class="dv">1</span>, <span class="at">cex =</span> <span class="dv">4</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb922-14"><a href="model-diagnostics.html#cb922-14" tabindex="-1"></a><span class="fu">abline</span>(ex_model, <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb922-15"><a href="model-diagnostics.html#cb922-15" tabindex="-1"></a><span class="fu">abline</span>(model_1, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb922-16"><a href="model-diagnostics.html#cb922-16" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomleft&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;Original Data&quot;</span>, <span class="st">&quot;Added Point&quot;</span>),</span>
<span id="cb922-17"><a href="model-diagnostics.html#cb922-17" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;dodgerblue&quot;</span>, <span class="st">&quot;darkorange&quot;</span>))</span>
<span id="cb922-18"><a href="model-diagnostics.html#cb922-18" tabindex="-1"></a></span>
<span id="cb922-19"><a href="model-diagnostics.html#cb922-19" tabindex="-1"></a><span class="co"># high leverage, small residual, small influence</span></span>
<span id="cb922-20"><a href="model-diagnostics.html#cb922-20" tabindex="-1"></a>point_2 <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">18</span>, <span class="sc">-</span><span class="fl">5.7</span>)</span>
<span id="cb922-21"><a href="model-diagnostics.html#cb922-21" tabindex="-1"></a>ex_data_2 <span class="ot">=</span> <span class="fu">rbind</span>(ex_data, point_2)</span>
<span id="cb922-22"><a href="model-diagnostics.html#cb922-22" tabindex="-1"></a>model_2 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> ex_data_2)</span>
<span id="cb922-23"><a href="model-diagnostics.html#cb922-23" tabindex="-1"></a><span class="fu">plot</span>(y <span class="sc">~</span> x, <span class="at">data =</span> ex_data_2, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>,</span>
<span id="cb922-24"><a href="model-diagnostics.html#cb922-24" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;High Leverage, Small Residual, Small Influence&quot;</span>)</span>
<span id="cb922-25"><a href="model-diagnostics.html#cb922-25" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x =</span> point_2[<span class="dv">1</span>], <span class="at">y =</span> point_2[<span class="dv">2</span>], <span class="at">pch =</span> <span class="dv">1</span>, <span class="at">cex =</span> <span class="dv">4</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb922-26"><a href="model-diagnostics.html#cb922-26" tabindex="-1"></a><span class="fu">abline</span>(ex_model, <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb922-27"><a href="model-diagnostics.html#cb922-27" tabindex="-1"></a><span class="fu">abline</span>(model_2, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb922-28"><a href="model-diagnostics.html#cb922-28" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomleft&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;Original Data&quot;</span>, <span class="st">&quot;Added Point&quot;</span>),</span>
<span id="cb922-29"><a href="model-diagnostics.html#cb922-29" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;dodgerblue&quot;</span>, <span class="st">&quot;darkorange&quot;</span>))</span>
<span id="cb922-30"><a href="model-diagnostics.html#cb922-30" tabindex="-1"></a></span>
<span id="cb922-31"><a href="model-diagnostics.html#cb922-31" tabindex="-1"></a><span class="co"># high leverage, large residual, large influence</span></span>
<span id="cb922-32"><a href="model-diagnostics.html#cb922-32" tabindex="-1"></a>point_3 <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">14</span>, <span class="fl">5.1</span>)</span>
<span id="cb922-33"><a href="model-diagnostics.html#cb922-33" tabindex="-1"></a>ex_data_3 <span class="ot">=</span> <span class="fu">rbind</span>(ex_data, point_3)</span>
<span id="cb922-34"><a href="model-diagnostics.html#cb922-34" tabindex="-1"></a>model_3 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> ex_data_3)</span>
<span id="cb922-35"><a href="model-diagnostics.html#cb922-35" tabindex="-1"></a><span class="fu">plot</span>(y <span class="sc">~</span> x, <span class="at">data =</span> ex_data_3, <span class="at">cex =</span> <span class="dv">2</span>, <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">12</span>),</span>
<span id="cb922-36"><a href="model-diagnostics.html#cb922-36" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;High Leverage, Large Residual, Large Influence&quot;</span>)</span>
<span id="cb922-37"><a href="model-diagnostics.html#cb922-37" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x =</span> point_3[<span class="dv">1</span>], <span class="at">y =</span> point_3[<span class="dv">2</span>], <span class="at">pch =</span> <span class="dv">1</span>, <span class="at">cex =</span> <span class="dv">4</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb922-38"><a href="model-diagnostics.html#cb922-38" tabindex="-1"></a><span class="fu">abline</span>(ex_model, <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb922-39"><a href="model-diagnostics.html#cb922-39" tabindex="-1"></a><span class="fu">abline</span>(model_3, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb922-40"><a href="model-diagnostics.html#cb922-40" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomleft&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;Original Data&quot;</span>, <span class="st">&quot;Added Point&quot;</span>),</span>
<span id="cb922-41"><a href="model-diagnostics.html#cb922-41" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;dodgerblue&quot;</span>, <span class="st">&quot;darkorange&quot;</span>))</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unusual_obs_plot-1.png" width="1440" style="display: block; margin: auto;" /></p>
<p>The blue solid line in each plot is a regression fit to the 10 original data points stored in <code>ex_data</code>. The dashed orange line in each plot is the result of adding a single point to the original data in <code>ex_data</code>. This additional point is indicated by the circled point.</p>
<p>The slope of the regression for the original ten points, the solid blue line, is given by:</p>
<div class="sourceCode" id="cb923"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb923-1"><a href="model-diagnostics.html#cb923-1" tabindex="-1"></a><span class="fu">coef</span>(ex_model)[<span class="dv">2</span>]</span></code></pre></div>
<pre><code>##          x 
## -0.9696033</code></pre>
<p>The added point in the first plot has a <em>small</em> effect on the slope, which becomes:</p>
<div class="sourceCode" id="cb925"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb925-1"><a href="model-diagnostics.html#cb925-1" tabindex="-1"></a><span class="fu">coef</span>(model_1)[<span class="dv">2</span>]</span></code></pre></div>
<pre><code>##          x 
## -0.9749534</code></pre>
<p>We will say that this point has low leverage, is an outlier due to its large residual, but has small influence.</p>
<p>The added point in the second plot also has a <em>small</em> effect on the slope, which is:</p>
<div class="sourceCode" id="cb927"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb927-1"><a href="model-diagnostics.html#cb927-1" tabindex="-1"></a><span class="fu">coef</span>(model_2)[<span class="dv">2</span>]</span></code></pre></div>
<pre><code>##          x 
## -0.9507397</code></pre>
<p>We will say that this point has high leverage, is not an outlier due to its small residual, and has a very small influence.</p>
<p>Lastly, the added point in the third plot has a <em>large</em> effect on the slope, which is now:</p>
<div class="sourceCode" id="cb929"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb929-1"><a href="model-diagnostics.html#cb929-1" tabindex="-1"></a><span class="fu">coef</span>(model_3)[<span class="dv">2</span>]</span></code></pre></div>
<pre><code>##          x 
## -0.5892241</code></pre>
<p>This added point is influential. It both has high leverage, and is an outlier due to its large residual.</p>
<p>We’ve now mentioned three new concepts: leverage, outliers, and influential points, each of which we will discuss in detail.</p>
<div id="leverage" class="section level3 hasAnchor" number="13.3.1">
<h3><span class="header-section-number">13.3.1</span> Leverage<a href="model-diagnostics.html#leverage" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A data point with high <strong>leverage</strong>, is a data point that <em>could</em> have a large influence when fitting the model.</p>
<p>Recall that,</p>
<p><span class="math display">\[
\hat{\beta} = \left(X^\top X \right)^{-1} X^\top y.
\]</span></p>
<p>Thus,</p>
<p><span class="math display">\[
\hat{y} = X \hat{\beta}   = X \left(X^\top X \right)^{-1} X^\top y
\]</span></p>
<p>Now we define,</p>
<p><span class="math display">\[
H = X \left(X^\top X\right)^{-1} X^\top
\]</span></p>
<p>which we will refer to as the <em>hat matrix</em>. The hat matrix is used to project onto the subspace spanned by the columns of <span class="math inline">\(X\)</span>. It is also simply known as a projection matrix.</p>
<p>The hat matrix is a matrix that takes the original <span class="math inline">\(y\)</span> values, and adds a hat!</p>
<p><span class="math display">\[
\hat{y} = H y
\]</span></p>
<p>The diagonal elements of this matrix are called the <strong>leverages</strong></p>
<p><span class="math display">\[
H_{ii} = h_i,
\]</span></p>
<p>where <span class="math inline">\(h_i\)</span> is the leverage for the <span class="math inline">\(i\)</span>th observation.</p>
<p>Large values of <span class="math inline">\(h_i\)</span> indicate extreme values in <span class="math inline">\(X\)</span>, which may influence regression. Note that leverages only depend on <span class="math inline">\(X\)</span>.</p>
<p>Here, <span class="math inline">\(p\)</span>, the number of <span class="math inline">\(\beta\)</span>s, is also the trace (and rank) of the hat matrix.</p>
<p><span class="math display">\[
\sum_{i = 1}^n h_i = p
\]</span></p>
<p>What is a value of <span class="math inline">\(h_i\)</span> that would be considered large? There is no exact answer to this question. A common heuristic would be to compare each leverage to two times the average leverage. A leverage larger than this is considered an observation to be aware of. That is, if</p>
<p><span class="math display">\[
h_i &gt; 2 \bar{h}
\]</span></p>
<p>we say that observation <span class="math inline">\(i\)</span> has large leverage. Here,</p>
<p><span class="math display">\[
\bar{h} = \frac{\sum_{i = 1}^n h_i}{n} = \frac{p}{n}.
\]</span></p>
<p>For simple linear regression, the leverage for each point is given by</p>
<p><span class="math display">\[
h_i = \frac{1}{n} + \frac{(x_i - \bar{x})^2}{S_{xx}}.
\]</span></p>
<p>This expression should be familiar. (Think back to inference for SLR.) It suggests that the large leverages occur when <span class="math inline">\(x\)</span> values are far from their mean. Recall that the regression goes through the point <span class="math inline">\((\bar{x},\bar{y})\)</span>.</p>
<p>There are multiple ways to find leverages in <code>R</code>.</p>
<div class="sourceCode" id="cb931"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb931-1"><a href="model-diagnostics.html#cb931-1" tabindex="-1"></a>lev_ex <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb931-2"><a href="model-diagnostics.html#cb931-2" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">7</span>, <span class="dv">4</span>, <span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">8</span>),</span>
<span id="cb931-3"><a href="model-diagnostics.html#cb931-3" tabindex="-1"></a>  <span class="at">x2 =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">2</span>),</span>
<span id="cb931-4"><a href="model-diagnostics.html#cb931-4" tabindex="-1"></a>  <span class="at">y  =</span> <span class="fu">c</span>(<span class="dv">11</span>, <span class="dv">15</span>, <span class="dv">13</span>, <span class="dv">14</span>, <span class="dv">0</span>, <span class="dv">19</span>, <span class="dv">16</span>, <span class="dv">8</span>))</span>
<span id="cb931-5"><a href="model-diagnostics.html#cb931-5" tabindex="-1"></a></span>
<span id="cb931-6"><a href="model-diagnostics.html#cb931-6" tabindex="-1"></a><span class="fu">plot</span>(x2 <span class="sc">~</span> x1, <span class="at">data =</span> lev_ex, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb931-7"><a href="model-diagnostics.html#cb931-7" tabindex="-1"></a><span class="fu">points</span>(<span class="dv">7</span>, <span class="dv">3</span>, <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-32-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Here we’ve created some multivariate data. Notice that we have plotted the <span class="math inline">\(x\)</span> values, not the <span class="math inline">\(y\)</span> values. The red point is <span class="math inline">\((7, 3)\)</span> which is the mean of <code>x1</code> and the mean of <code>x2</code> respectively.</p>
<p>We could calculate the leverages using the expressions defined above. We first create the <span class="math inline">\(X\)</span> matrix, then calculate <span class="math inline">\(H\)</span> as defined, and extract the diagonal elements.</p>
<div class="sourceCode" id="cb932"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb932-1"><a href="model-diagnostics.html#cb932-1" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">8</span>), lev_ex<span class="sc">$</span>x1, lev_ex<span class="sc">$</span>x2)</span>
<span id="cb932-2"><a href="model-diagnostics.html#cb932-2" tabindex="-1"></a>H <span class="ot">=</span> X <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X) <span class="sc">%*%</span> <span class="fu">t</span>(X)</span>
<span id="cb932-3"><a href="model-diagnostics.html#cb932-3" tabindex="-1"></a><span class="fu">diag</span>(H)</span></code></pre></div>
<pre><code>## [1] 0.6000 0.3750 0.2875 0.1250 0.4000 0.2125 0.5875 0.4125</code></pre>
<p>Notice here, we have two predictors, so the regression would have 3 <span class="math inline">\(\beta\)</span> parameters, so the sum of the diagonal elements is 3.</p>
<div class="sourceCode" id="cb934"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb934-1"><a href="model-diagnostics.html#cb934-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">diag</span>(H))</span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<p>Alternatively, the method we will use more often, is to simply fit a regression, then use the <code>hatvalues()</code> function, which returns the leverages.</p>
<div class="sourceCode" id="cb936"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb936-1"><a href="model-diagnostics.html#cb936-1" tabindex="-1"></a>lev_fit <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> ., <span class="at">data =</span> lev_ex)</span>
<span id="cb936-2"><a href="model-diagnostics.html#cb936-2" tabindex="-1"></a><span class="fu">hatvalues</span>(lev_fit)</span></code></pre></div>
<pre><code>##      1      2      3      4      5      6      7      8 
## 0.6000 0.3750 0.2875 0.1250 0.4000 0.2125 0.5875 0.4125</code></pre>
<p>Again, note that here we have “used” the <span class="math inline">\(y\)</span> values to fit the regression, but <code>R</code> still ignores them when calculating the leverages, as leverages only depend on the <span class="math inline">\(x\)</span> values.</p>
<div class="sourceCode" id="cb938"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb938-1"><a href="model-diagnostics.html#cb938-1" tabindex="-1"></a><span class="fu">coef</span>(lev_fit)</span></code></pre></div>
<pre><code>## (Intercept)          x1          x2 
##         3.7        -0.7         4.4</code></pre>
<p>Let’s see what happens to these coefficients when we modify the <code>y</code> value of the point with the highest leverage.</p>
<div class="sourceCode" id="cb940"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb940-1"><a href="model-diagnostics.html#cb940-1" tabindex="-1"></a><span class="fu">which.max</span>(<span class="fu">hatvalues</span>(lev_fit))</span></code></pre></div>
<pre><code>## 1 
## 1</code></pre>
<div class="sourceCode" id="cb942"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb942-1"><a href="model-diagnostics.html#cb942-1" tabindex="-1"></a>lev_ex[<span class="fu">which.max</span>(<span class="fu">hatvalues</span>(lev_fit)),]</span></code></pre></div>
<pre><code>##   x1 x2  y
## 1  0  1 11</code></pre>
<p>We see that the original <code>y</code> value is 11. We’ll create a copy of the data, and modify this point to have a <code>y</code> value of <code>20</code>.</p>
<div class="sourceCode" id="cb944"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb944-1"><a href="model-diagnostics.html#cb944-1" tabindex="-1"></a>lev_ex_1 <span class="ot">=</span> lev_ex</span>
<span id="cb944-2"><a href="model-diagnostics.html#cb944-2" tabindex="-1"></a>lev_ex_1<span class="sc">$</span>y[<span class="dv">1</span>] <span class="ot">=</span> <span class="dv">20</span></span>
<span id="cb944-3"><a href="model-diagnostics.html#cb944-3" tabindex="-1"></a><span class="fu">lm</span>(y <span class="sc">~</span> ., <span class="at">data =</span> lev_ex_1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ ., data = lev_ex_1)
## 
## Coefficients:
## (Intercept)           x1           x2  
##       8.875       -1.375        4.625</code></pre>
<p>Notice the <strong>large</strong> changes in the coefficients. Also notice that each of the coefficients has changed in some way. Note that the leverages of the points would not have changed, as we have not modified any of the <span class="math inline">\(x\)</span> values.</p>
<p>Now let’s see what happens to these coefficients when we modify the <code>y</code> value of the point with the lowest leverage.</p>
<div class="sourceCode" id="cb946"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb946-1"><a href="model-diagnostics.html#cb946-1" tabindex="-1"></a><span class="fu">which.min</span>(<span class="fu">hatvalues</span>(lev_fit))</span></code></pre></div>
<pre><code>## 4 
## 4</code></pre>
<div class="sourceCode" id="cb948"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb948-1"><a href="model-diagnostics.html#cb948-1" tabindex="-1"></a>lev_ex[<span class="fu">which.min</span>(<span class="fu">hatvalues</span>(lev_fit)),]</span></code></pre></div>
<pre><code>##   x1 x2  y
## 4  7  3 14</code></pre>
<p>We see that the original <code>y</code> value is 14. We’ll again create a copy of the data, and modify this point to have a <code>y</code> value of <code>30</code>.</p>
<div class="sourceCode" id="cb950"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb950-1"><a href="model-diagnostics.html#cb950-1" tabindex="-1"></a>lev_ex_2 <span class="ot">=</span> lev_ex</span>
<span id="cb950-2"><a href="model-diagnostics.html#cb950-2" tabindex="-1"></a>lev_ex_2<span class="sc">$</span>y[<span class="dv">4</span>] <span class="ot">=</span> <span class="dv">30</span></span>
<span id="cb950-3"><a href="model-diagnostics.html#cb950-3" tabindex="-1"></a><span class="fu">lm</span>(y <span class="sc">~</span> ., <span class="at">data =</span> lev_ex_2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ ., data = lev_ex_2)
## 
## Coefficients:
## (Intercept)           x1           x2  
##         5.7         -0.7          4.4</code></pre>
<p>This time despite a large change in the <code>y</code> value, there is only small change in the coefficients. Also, only the intercept has changed!</p>
<div class="sourceCode" id="cb952"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb952-1"><a href="model-diagnostics.html#cb952-1" tabindex="-1"></a><span class="fu">mean</span>(lev_ex<span class="sc">$</span>x1)</span></code></pre></div>
<pre><code>## [1] 7</code></pre>
<div class="sourceCode" id="cb954"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb954-1"><a href="model-diagnostics.html#cb954-1" tabindex="-1"></a><span class="fu">mean</span>(lev_ex<span class="sc">$</span>x2)</span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb956"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb956-1"><a href="model-diagnostics.html#cb956-1" tabindex="-1"></a>lev_ex[<span class="dv">4</span>,]</span></code></pre></div>
<pre><code>##   x1 x2  y
## 4  7  3 14</code></pre>
<p>Notice that this point was the mean of both of the predictors.</p>
<p>Returning to our three plots, each with an added point, we can calculate the leverages for each. Note that the 11th data point each time is the added data point.</p>
<div class="sourceCode" id="cb958"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb958-1"><a href="model-diagnostics.html#cb958-1" tabindex="-1"></a><span class="fu">hatvalues</span>(model_1)</span></code></pre></div>
<pre><code>##          1          2          3          4          5          6          7 
## 0.33534597 0.23860732 0.16610842 0.11784927 0.09382988 0.09405024 0.11851036 
##          8          9         10         11 
## 0.16721022 0.24014985 0.33732922 0.09100926</code></pre>
<div class="sourceCode" id="cb960"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb960-1"><a href="model-diagnostics.html#cb960-1" tabindex="-1"></a><span class="fu">hatvalues</span>(model_2)</span></code></pre></div>
<pre><code>##          1          2          3          4          5          6          7 
## 0.23238866 0.18663968 0.14979757 0.12186235 0.10283401 0.09271255 0.09149798 
##          8          9         10         11 
## 0.09919028 0.11578947 0.14129555 0.66599190</code></pre>
<div class="sourceCode" id="cb962"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb962-1"><a href="model-diagnostics.html#cb962-1" tabindex="-1"></a><span class="fu">hatvalues</span>(model_3)</span></code></pre></div>
<pre><code>##          1          2          3          4          5          6          7 
## 0.27852761 0.21411043 0.16319018 0.12576687 0.10184049 0.09141104 0.09447853 
##          8          9         10         11 
## 0.11104294 0.14110429 0.18466258 0.49386503</code></pre>
<p>Are any of these large?</p>
<div class="sourceCode" id="cb964"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb964-1"><a href="model-diagnostics.html#cb964-1" tabindex="-1"></a><span class="fu">hatvalues</span>(model_1) <span class="sc">&gt;</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">mean</span>(<span class="fu">hatvalues</span>(model_1))</span></code></pre></div>
<pre><code>##     1     2     3     4     5     6     7     8     9    10    11 
## FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE</code></pre>
<div class="sourceCode" id="cb966"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb966-1"><a href="model-diagnostics.html#cb966-1" tabindex="-1"></a><span class="fu">hatvalues</span>(model_2) <span class="sc">&gt;</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">mean</span>(<span class="fu">hatvalues</span>(model_2))</span></code></pre></div>
<pre><code>##     1     2     3     4     5     6     7     8     9    10    11 
## FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE</code></pre>
<div class="sourceCode" id="cb968"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb968-1"><a href="model-diagnostics.html#cb968-1" tabindex="-1"></a><span class="fu">hatvalues</span>(model_3) <span class="sc">&gt;</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">mean</span>(<span class="fu">hatvalues</span>(model_3))</span></code></pre></div>
<pre><code>##     1     2     3     4     5     6     7     8     9    10    11 
## FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE</code></pre>
<p>We see that in the second and third plots, the added point is a point of high leverage. Recall that only in the third plot did that have an influence on the regression. To understand why, we’ll need to discuss outliers.</p>
</div>
<div id="outliers" class="section level3 hasAnchor" number="13.3.2">
<h3><span class="header-section-number">13.3.2</span> Outliers<a href="model-diagnostics.html#outliers" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Outliers are points which do not fit the model well. They may or may not have a large effect on the model. To identify outliers, we will look for observations with large residuals.</p>
<p>Note,</p>
<p><span class="math display">\[
e = y - \hat{y} = Iy - Hy = (I - H) y
\]</span></p>
<p>Then, under the assumptions of linear regression,</p>
<p><span class="math display">\[
\text{Var}(e_i) = (1 - h_i) \sigma^2
\]</span></p>
<p>and thus estimating <span class="math inline">\(\sigma^2\)</span> with <span class="math inline">\(s_e^2\)</span> gives</p>
<p><span class="math display">\[
\text{SE}[e_i] = s_e \sqrt{(1 - h_i)}.
\]</span></p>
<p>We can then look at the <strong>standardized residual</strong> for each observation, <span class="math inline">\(i = 1, 2, \ldots n\)</span>,</p>
<p><span class="math display">\[
r_i = \frac{e_i}{s_e\sqrt{1 - h_i}} \overset{approx}{\sim} N(\mu = 0, \sigma^ 2 = 1)
\]</span></p>
<p>when <span class="math inline">\(n\)</span> is large.</p>
<p>We can use this fact to identify “large” residuals. For example, standardized residuals greater than 2 in magnitude should only happen approximately 5 percent of the time.</p>
<p>Returning again to our three plots, each with an added point, we can calculate the residuals and standardized residuals for each. Standardized residuals can be obtained in <code>R</code> by using <code>rstandard()</code> where we would normally use <code>resid()</code>.</p>
<div class="sourceCode" id="cb970"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb970-1"><a href="model-diagnostics.html#cb970-1" tabindex="-1"></a><span class="fu">resid</span>(model_1)</span></code></pre></div>
<pre><code>##          1          2          3          4          5          6          7 
##  0.4949887 -1.4657145 -0.5629345 -0.3182468 -0.5718877 -1.1073271  0.4852728 
##          8          9         10         11 
## -1.1459548  0.9420814 -1.1641029  4.4138254</code></pre>
<div class="sourceCode" id="cb972"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb972-1"><a href="model-diagnostics.html#cb972-1" tabindex="-1"></a><span class="fu">rstandard</span>(model_1)</span></code></pre></div>
<pre><code>##          1          2          3          4          5          6          7 
##  0.3464701 -0.9585470 -0.3517802 -0.1933575 -0.3428264 -0.6638841  0.2949482 
##          8          9         10         11 
## -0.7165857  0.6167268 -0.8160389  2.6418234</code></pre>
<div class="sourceCode" id="cb974"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb974-1"><a href="model-diagnostics.html#cb974-1" tabindex="-1"></a><span class="fu">rstandard</span>(model_1)[<span class="fu">abs</span>(<span class="fu">rstandard</span>(model_1)) <span class="sc">&gt;</span> <span class="dv">2</span>]</span></code></pre></div>
<pre><code>##       11 
## 2.641823</code></pre>
<p>In the first plot, we see that the 11th point, the added point, is a large standardized residual.</p>
<div class="sourceCode" id="cb976"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb976-1"><a href="model-diagnostics.html#cb976-1" tabindex="-1"></a><span class="fu">resid</span>(model_2)</span></code></pre></div>
<pre><code>##           1           2           3           4           5           6 
##  1.03288292 -0.95203397 -0.07346766  0.14700626 -0.13084829 -0.69050140 
##           7           8           9          10          11 
##  0.87788484 -0.77755647  1.28626601 -0.84413207  0.12449986</code></pre>
<div class="sourceCode" id="cb978"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb978-1"><a href="model-diagnostics.html#cb978-1" tabindex="-1"></a><span class="fu">rstandard</span>(model_2)</span></code></pre></div>
<pre><code>##           1           2           3           4           5           6 
##  1.41447023 -1.26655590 -0.09559792  0.18822094 -0.16574677 -0.86977220 
##           7           8           9          10          11 
##  1.10506546 -0.98294409  1.64121833 -1.09295417  0.25846620</code></pre>
<div class="sourceCode" id="cb980"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb980-1"><a href="model-diagnostics.html#cb980-1" tabindex="-1"></a><span class="fu">rstandard</span>(model_2)[<span class="fu">abs</span>(<span class="fu">rstandard</span>(model_2)) <span class="sc">&gt;</span> <span class="dv">2</span>]</span></code></pre></div>
<pre><code>## named numeric(0)</code></pre>
<p>In the second plot, we see that there are no points with large standardized residuals.</p>
<div class="sourceCode" id="cb982"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb982-1"><a href="model-diagnostics.html#cb982-1" tabindex="-1"></a><span class="fu">resid</span>(model_3)</span></code></pre></div>
<pre><code>##           1           2           3           4           5           6 
##  2.30296166 -0.04347087  0.47357980  0.33253808 -0.30683212 -1.22800087 
##           7           8           9          10          11 
## -0.02113027 -2.03808722 -0.33578039 -2.82769411  3.69191633</code></pre>
<div class="sourceCode" id="cb984"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb984-1"><a href="model-diagnostics.html#cb984-1" tabindex="-1"></a><span class="fu">rstandard</span>(model_3)</span></code></pre></div>
<pre><code>##           1           2           3           4           5           6 
##  1.41302755 -0.02555591  0.26980722  0.18535382 -0.16873216 -0.67141143 
##           7           8           9          10          11 
## -0.01157256 -1.12656475 -0.18882474 -1.63206526  2.70453408</code></pre>
<div class="sourceCode" id="cb986"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb986-1"><a href="model-diagnostics.html#cb986-1" tabindex="-1"></a><span class="fu">rstandard</span>(model_3)[<span class="fu">abs</span>(<span class="fu">rstandard</span>(model_3)) <span class="sc">&gt;</span> <span class="dv">2</span>]</span></code></pre></div>
<pre><code>##       11 
## 2.704534</code></pre>
<p>In the last plot, we see that the 11th point, the added point, is a large standardized residual.</p>
<p>Recall that the added point in plots two and three were both high leverage, but now only the point in plot three has a large residual. We will now combine this information and discuss influence.</p>
</div>
<div id="influence" class="section level3 hasAnchor" number="13.3.3">
<h3><span class="header-section-number">13.3.3</span> Influence<a href="model-diagnostics.html#influence" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As we have now seen in the three plots, some outliers only change the regression a small amount (plot one) and some outliers have a large effect on the regression (plot three). Observations that fall into the latter category, points with (some combination of) <em>high leverage</em> <strong>and</strong> <em>large residual</em>, we will call <strong>influential</strong>.</p>
<p>A common measure of influence is <strong>Cook’s Distance</strong>, which is defined as</p>
<p><span class="math display">\[
  D_i = \frac{1}{p}r_i^2\frac{h_i}{1-{h_i}}.
\]</span></p>
<p>Notice that this is a function of both <em>leverage</em> and <em>standardized residuals</em>.</p>
<p>A Cook’s Distance is often considered large if</p>
<p><span class="math display">\[
D_i &gt; \frac{4}{n}
\]</span></p>
<p>and an observation with a large Cook’s Distance is called influential. This is again simply a heuristic, and not an exact rule.</p>
<p>The Cook’s distance for each point of a regression can be calculated using <code>cooks.distance()</code> which is a default function in <code>R</code>. Let’s look for influential points in the three plots we had been considering.</p>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-47-1.png" width="1440" style="display: block; margin: auto;" /></p>
<p>Recall that the circled points in each plot have different characteristics:</p>
<ul>
<li>Plot One: low leverage, large residual.</li>
<li>Plot Two: high leverage, small residual.</li>
<li>Plot Three: high leverage, large residual.</li>
</ul>
<p>We’ll now directly check if each of these is influential.</p>
<div class="sourceCode" id="cb988"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb988-1"><a href="model-diagnostics.html#cb988-1" tabindex="-1"></a><span class="fu">cooks.distance</span>(model_1)[<span class="dv">11</span>] <span class="sc">&gt;</span> <span class="dv">4</span> <span class="sc">/</span> <span class="fu">length</span>(<span class="fu">cooks.distance</span>(model_1))</span></code></pre></div>
<pre><code>##    11 
## FALSE</code></pre>
<div class="sourceCode" id="cb990"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb990-1"><a href="model-diagnostics.html#cb990-1" tabindex="-1"></a><span class="fu">cooks.distance</span>(model_2)[<span class="dv">11</span>] <span class="sc">&gt;</span> <span class="dv">4</span> <span class="sc">/</span> <span class="fu">length</span>(<span class="fu">cooks.distance</span>(model_2))</span></code></pre></div>
<pre><code>##    11 
## FALSE</code></pre>
<div class="sourceCode" id="cb992"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb992-1"><a href="model-diagnostics.html#cb992-1" tabindex="-1"></a><span class="fu">cooks.distance</span>(model_3)[<span class="dv">11</span>] <span class="sc">&gt;</span> <span class="dv">4</span> <span class="sc">/</span> <span class="fu">length</span>(<span class="fu">cooks.distance</span>(model_3))</span></code></pre></div>
<pre><code>##   11 
## TRUE</code></pre>
<p>And, as expected, the added point in the third plot, with high leverage and a large residual, is considered influential!</p>
</div>
</div>
<div id="data-analysis-examples" class="section level2 hasAnchor" number="13.4">
<h2><span class="header-section-number">13.4</span> Data Analysis Examples<a href="model-diagnostics.html#data-analysis-examples" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="good-diagnostics" class="section level3 hasAnchor" number="13.4.1">
<h3><span class="header-section-number">13.4.1</span> Good Diagnostics<a href="model-diagnostics.html#good-diagnostics" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Last chapter we fit an additive regression to the <code>mtcars</code> data with <code>mpg</code> as the response and <code>hp</code> and <code>am</code> as predictors. Let’s perform some diagnostics on this model.</p>
<p>First, fit the model as we did last chapter.</p>
<div class="sourceCode" id="cb994"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb994-1"><a href="model-diagnostics.html#cb994-1" tabindex="-1"></a>mpg_hp_add <span class="ot">=</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> hp <span class="sc">+</span> am, <span class="at">data =</span> mtcars)</span></code></pre></div>
<div class="sourceCode" id="cb995"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb995-1"><a href="model-diagnostics.html#cb995-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">fitted</span>(mpg_hp_add), <span class="fu">resid</span>(mpg_hp_add), <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">pch =</span> <span class="dv">20</span>,</span>
<span id="cb995-2"><a href="model-diagnostics.html#cb995-2" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Fitted&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Residual&quot;</span>,</span>
<span id="cb995-3"><a href="model-diagnostics.html#cb995-3" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;mtcars: Fitted versus Residuals&quot;</span>)</span>
<span id="cb995-4"><a href="model-diagnostics.html#cb995-4" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-50-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The fitted versus residuals plot looks good. We don’t see any obvious pattern, and the variance looks roughly constant. (Maybe a little larger for large fitted values, but not enough to worry about.)</p>
<div class="sourceCode" id="cb996"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb996-1"><a href="model-diagnostics.html#cb996-1" tabindex="-1"></a><span class="fu">bptest</span>(mpg_hp_add)</span></code></pre></div>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  mpg_hp_add
## BP = 7.5858, df = 2, p-value = 0.02253</code></pre>
<p>The Breusch-Pagan test verifies this, at least for a small <span class="math inline">\(\alpha\)</span> value.</p>
<div class="sourceCode" id="cb998"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb998-1"><a href="model-diagnostics.html#cb998-1" tabindex="-1"></a><span class="fu">qqnorm</span>(<span class="fu">resid</span>(mpg_hp_add), <span class="at">col =</span> <span class="st">&quot;darkgrey&quot;</span>)</span>
<span id="cb998-2"><a href="model-diagnostics.html#cb998-2" tabindex="-1"></a><span class="fu">qqline</span>(<span class="fu">resid</span>(mpg_hp_add), <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-52-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The Q-Q plot looks extremely good and the Shapiro-Wilk test agrees.</p>
<div class="sourceCode" id="cb999"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb999-1"><a href="model-diagnostics.html#cb999-1" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">resid</span>(mpg_hp_add))</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resid(mpg_hp_add)
## W = 0.96485, p-value = 0.3706</code></pre>
<div class="sourceCode" id="cb1001"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1001-1"><a href="model-diagnostics.html#cb1001-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">hatvalues</span>(mpg_hp_add) <span class="sc">&gt;</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">mean</span>(<span class="fu">hatvalues</span>(mpg_hp_add)))</span></code></pre></div>
<pre><code>## [1] 2</code></pre>
<p>We see that there are two points of large leverage.</p>
<div class="sourceCode" id="cb1003"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1003-1"><a href="model-diagnostics.html#cb1003-1" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">abs</span>(<span class="fu">rstandard</span>(mpg_hp_add)) <span class="sc">&gt;</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>There is also one point with a large residual. Do these result in any points that are considered influential?</p>
<div class="sourceCode" id="cb1005"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1005-1"><a href="model-diagnostics.html#cb1005-1" tabindex="-1"></a>cd_mpg_hp_add <span class="ot">=</span> <span class="fu">cooks.distance</span>(mpg_hp_add)</span>
<span id="cb1005-2"><a href="model-diagnostics.html#cb1005-2" tabindex="-1"></a><span class="fu">sum</span>(cd_mpg_hp_add <span class="sc">&gt;</span> <span class="dv">4</span> <span class="sc">/</span> <span class="fu">length</span>(cd_mpg_hp_add))</span></code></pre></div>
<pre><code>## [1] 2</code></pre>
<div class="sourceCode" id="cb1007"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1007-1"><a href="model-diagnostics.html#cb1007-1" tabindex="-1"></a>large_cd_mpg <span class="ot">=</span> cd_mpg_hp_add <span class="sc">&gt;</span> <span class="dv">4</span> <span class="sc">/</span> <span class="fu">length</span>(cd_mpg_hp_add)</span>
<span id="cb1007-2"><a href="model-diagnostics.html#cb1007-2" tabindex="-1"></a>cd_mpg_hp_add[large_cd_mpg]</span></code></pre></div>
<pre><code>## Toyota Corolla  Maserati Bora 
##      0.1772555      0.3447994</code></pre>
<p>We find two influential points. Interestingly, they are <strong>very</strong> different cars.</p>
<div class="sourceCode" id="cb1009"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1009-1"><a href="model-diagnostics.html#cb1009-1" tabindex="-1"></a><span class="fu">coef</span>(mpg_hp_add)</span></code></pre></div>
<pre><code>## (Intercept)          hp          am 
##  26.5849137  -0.0588878   5.2770853</code></pre>
<p>Since the diagnostics looked good, there isn’t much need to worry about these two points, but let’s see how much the coefficients change if we remove them.</p>
<div class="sourceCode" id="cb1011"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1011-1"><a href="model-diagnostics.html#cb1011-1" tabindex="-1"></a>mpg_hp_add_fix <span class="ot">=</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> hp <span class="sc">+</span> am,</span>
<span id="cb1011-2"><a href="model-diagnostics.html#cb1011-2" tabindex="-1"></a>                    <span class="at">data =</span> mtcars,</span>
<span id="cb1011-3"><a href="model-diagnostics.html#cb1011-3" tabindex="-1"></a>                    <span class="at">subset =</span> cd_mpg_hp_add <span class="sc">&lt;=</span> <span class="dv">4</span> <span class="sc">/</span> <span class="fu">length</span>(cd_mpg_hp_add))</span>
<span id="cb1011-4"><a href="model-diagnostics.html#cb1011-4" tabindex="-1"></a><span class="fu">coef</span>(mpg_hp_add_fix)</span></code></pre></div>
<pre><code>## (Intercept)          hp          am 
## 27.22190933 -0.06286249  4.29765867</code></pre>
<p>It seems there isn’t much of a change in the coefficients as a result of removing the supposed influential points. Notice we did not create a new dataset to accomplish this. We instead used the <code>subset</code> argument to <code>lm()</code>. Think about what the code <code>cd_mpg_hp_add &lt;= 4 / length(cd_mpg_hp_add)</code> does here.</p>
<div class="sourceCode" id="cb1013"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1013-1"><a href="model-diagnostics.html#cb1013-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb1013-2"><a href="model-diagnostics.html#cb1013-2" tabindex="-1"></a><span class="fu">plot</span>(mpg_hp_add)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-59-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Notice that calling <code>plot()</code> on a variable which stores an object created by <code>lm()</code> outputs four diagnostic plots by default. Use <code>?plot.lm</code> to learn more. The first two should already be familiar.</p>
</div>
<div id="suspect-diagnostics" class="section level3 hasAnchor" number="13.4.2">
<h3><span class="header-section-number">13.4.2</span> Suspect Diagnostics<a href="model-diagnostics.html#suspect-diagnostics" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s consider the model <code>big_model</code> from last chapter which was fit to the <code>autompg</code> dataset. It used <code>mpg</code> as the response, and considered many interaction terms between the predictors <code>disp</code>, <code>hp</code>, and <code>domestic</code>.</p>
<div class="sourceCode" id="cb1014"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1014-1"><a href="model-diagnostics.html#cb1014-1" tabindex="-1"></a><span class="fu">str</span>(autompg)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    383 obs. of  9 variables:
##  $ mpg     : num  18 15 18 16 17 15 14 14 14 15 ...
##  $ cyl     : Factor w/ 3 levels &quot;4&quot;,&quot;6&quot;,&quot;8&quot;: 3 3 3 3 3 3 3 3 3 3 ...
##  $ disp    : num  307 350 318 304 302 429 454 440 455 390 ...
##  $ hp      : num  130 165 150 150 140 198 220 215 225 190 ...
##  $ wt      : num  3504 3693 3436 3433 3449 ...
##  $ acc     : num  12 11.5 11 12 10.5 10 9 8.5 10 8.5 ...
##  $ year    : int  70 70 70 70 70 70 70 70 70 70 ...
##  $ origin  : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ domestic: num  1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<div class="sourceCode" id="cb1016"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1016-1"><a href="model-diagnostics.html#cb1016-1" tabindex="-1"></a>big_model <span class="ot">=</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> disp <span class="sc">*</span> hp <span class="sc">*</span> domestic, <span class="at">data =</span> autompg)</span></code></pre></div>
<div class="sourceCode" id="cb1017"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1017-1"><a href="model-diagnostics.html#cb1017-1" tabindex="-1"></a><span class="fu">qqnorm</span>(<span class="fu">resid</span>(big_model), <span class="at">col =</span> <span class="st">&quot;darkgrey&quot;</span>)</span>
<span id="cb1017-2"><a href="model-diagnostics.html#cb1017-2" tabindex="-1"></a><span class="fu">qqline</span>(<span class="fu">resid</span>(big_model), <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-63-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb1018"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1018-1"><a href="model-diagnostics.html#cb1018-1" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">resid</span>(big_model))</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resid(big_model)
## W = 0.96161, p-value = 1.824e-08</code></pre>
<p>Here both the Q-Q plot, and the Shapiro-Wilk test suggest that the normality assumption is violated.</p>
<div class="sourceCode" id="cb1020"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1020-1"><a href="model-diagnostics.html#cb1020-1" tabindex="-1"></a>big_mod_cd <span class="ot">=</span> <span class="fu">cooks.distance</span>(big_model)</span>
<span id="cb1020-2"><a href="model-diagnostics.html#cb1020-2" tabindex="-1"></a><span class="fu">sum</span>(big_mod_cd <span class="sc">&gt;</span> <span class="dv">4</span> <span class="sc">/</span> <span class="fu">length</span>(big_mod_cd))</span></code></pre></div>
<pre><code>## [1] 31</code></pre>
<p>Here, we find 31, so perhaps removing them will help!</p>
<div class="sourceCode" id="cb1022"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1022-1"><a href="model-diagnostics.html#cb1022-1" tabindex="-1"></a>big_model_fix <span class="ot">=</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> disp <span class="sc">*</span> hp <span class="sc">*</span> domestic,</span>
<span id="cb1022-2"><a href="model-diagnostics.html#cb1022-2" tabindex="-1"></a>                   <span class="at">data =</span> autompg,</span>
<span id="cb1022-3"><a href="model-diagnostics.html#cb1022-3" tabindex="-1"></a>                   <span class="at">subset =</span> big_mod_cd <span class="sc">&lt;</span> <span class="dv">4</span> <span class="sc">/</span> <span class="fu">length</span>(big_mod_cd))</span>
<span id="cb1022-4"><a href="model-diagnostics.html#cb1022-4" tabindex="-1"></a><span class="fu">qqnorm</span>(<span class="fu">resid</span>(big_model_fix), <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>)</span>
<span id="cb1022-5"><a href="model-diagnostics.html#cb1022-5" tabindex="-1"></a><span class="fu">qqline</span>(<span class="fu">resid</span>(big_model_fix), <span class="at">col =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-65-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb1023"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1023-1"><a href="model-diagnostics.html#cb1023-1" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">resid</span>(big_model_fix))</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resid(big_model_fix)
## W = 0.99035, p-value = 0.02068</code></pre>
<p>Removing these points results in a much better Q-Q plot, and now Shapiro-Wilk fails to reject for a low <span class="math inline">\(\alpha\)</span>.</p>
<p>We’ve now seen that sometimes modifying the data can fix issues with regression. However, next chapter, instead of modifying the data, we will modify the model via <em>transformations</em>.</p>
</div>
</div>
<div id="r-markdown-6" class="section level2 hasAnchor" number="13.5">
<h2><span class="header-section-number">13.5</span> <code>R</code> Markdown<a href="model-diagnostics.html#r-markdown-6" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The <code>R</code> Markdown file for this chapter can be found here:</p>
<ul>
<li><a href="diagnostics.Rmd" target="_blank"><code>diagnostics.Rmd</code></a></li>
</ul>
<p>The file was created using <code>R</code> version <code>4.4.1</code>.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="analysis-of-variance.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="transformations.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/daviddalpiaz/appliedstats/edit/master/diagnostics.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["applied_statistics.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
